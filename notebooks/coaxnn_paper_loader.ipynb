{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5g8SefEpeAf",
    "outputId": "1d0ded39-2f64-4a79-c389-7724ccfb58fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install langchain arxiv pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PDFMinerLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path pdfs/CoAxNN_Optimizing_on-device_deep_learning_with_conditional_approximate_neural_networks.pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3513291/3295520088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_putput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train_coaxnn_paper.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFMinerLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pdfs/CoAxNN_Optimizing_on-device_deep_learning_with_conditional_approximate_neural_networks.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, headers, extract_images, concatenate_pages)\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         self.parser = PDFMinerParser(\n\u001b[1;32m    296\u001b[0m             \u001b[0mextract_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate_pages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcatenate_pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File path %s is not a valid file or url\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File path pdfs/CoAxNN_Optimizing_on-device_deep_learning_with_conditional_approximate_neural_networks.pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_putput_name = \"train_coaxnn_paper.csv\"\n",
    "book = PDFMinerLoader(file_path='pdfs/CoAxNN_Optimizing_on-device_deep_learning_with_conditional_approximate_neural_networks.pdf').load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = book[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_text = book[0].page_content.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ix = 0\n",
    "# temp = all_text\n",
    "# while True:\n",
    "#     print(ix)\n",
    "#     all_text = all_text.replace(\"  \", \" \")\n",
    "#     if temp == all_text:\n",
    "#         break\n",
    "#     temp = all_text\n",
    "#     ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80987"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may have different influences on model prediction. Li\n",
      "et al. [11] proposed a flexible-rate filter pruning approach, FlexPruner,\n",
      "which automatically selects the number of filters to be pruned for\n",
      "each \n"
     ]
    }
   ],
   "source": [
    "print(book[0].page_content[10000:10200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# all paper without references\n",
    "paper_text = book[0].page_content[0:-12565]\n",
    "# print(book[0].page_content[0:-12565])\n",
    "\n",
    "# references\n",
    "references_text = book[0].page_content[-12565:]\n",
    "# print(book[0].page_content[-12565:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reference [1]: K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in:\\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition,\\n2016, pp. 770–778.',\n",
       " 'Reference [2]: Y. He, G. Kang, X. Dong, Y. Fu, Y. Yang, Soft filter pruning for accelerating\\nin: Proceedings of the Twenty-Seventh\\nIntelligence (IJCAI), 2018, pp.\\n\\ndeep convolutional neural networks,\\nInternational Joint Conference on Artificial\\n2234–2240.',\n",
       " 'Reference [3]: S.K. Esser, J.L. McKinstry, D. Bablani, R. Appuswamy, D.S. Modha, Learned\\nstep size quantization, in: International Conference on Learning Representations,\\n2020.',\n",
       " 'Reference [4]: Y. Guo, A. Yao, Y. Chen, Dynamic network surgery for efficient dnns,\\n\\nin:\\n\\nAdvances in Neural Information Processing Systems, Vol. 29, 2016.',\n",
       " 'Reference [5]: S. Han, J. Pool, J. Tran, W. Dally, Learning both weights and connections for\\nefficient neural network, in: Advances in Neural Information Processing Systems,\\nVol. 28, 2015.',\n",
       " 'Reference [6]: B. Hassibi, D. Stork, Second order derivatives for network pruning: Optimal brain\\nsurgeon, in: Advances in Neural Information Processing Systems, Vol. 5, 1992.',\n",
       " 'Reference [7]: B. Hassibi, D.G. Stork, G.J. Wolff, Optimal brain surgeon and general network\\npruning, in: IEEE International Conference on Neural Networks, IEEE, 1993, pp.\\n293–299.',\n",
       " 'Reference [8]: Y. He, X. Dong, G. Kang, Y. Fu, C. Yan, Y. Yang, Asymptotic soft filter pruning\\nfor deep convolutional neural networks, IEEE Trans. Cybern. 50 (8) (2019)\\n3594–3604.',\n",
       " 'Reference [9]: G. Li, X. Ma, X. Wang, L. Liu, J. Xue, X. Feng, Fusion-catalyzed pruning for\\noptimizing deep learning on intelligent edge devices, IEEE Trans. Comput.-Aided\\nDes. Integr. Circuits Syst. 39 (11) (2020) 3614–3626.',\n",
       " 'Reference [10]: J.-H. Luo, J. Wu, W. Lin, Thinet: A filter level pruning method for deep neural\\nnetwork compression, in: Proceedings of the IEEE International Conference on\\nComputer Vision, 2017, pp. 5058–5066.',\n",
       " 'Reference [11]: G. Li, X. Ma, X. Wang, H. Yue, J. Li, L. Liu, X. Feng, J. Xue, Optimizing deep\\nneural networks on intelligent edge accelerators via flexible-rate filter pruning,\\nJ. Syst. Archit. (2022) 102431.',\n",
       " 'Reference [12]: J. Plochaet, T. Goedemé, Hardware-aware pruning for FPGA deep learning\\naccelerators, in: Proceedings of the IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition, 2023, pp. 4481–4489.',\n",
       " 'Reference [13]: X. Zhuang, Y. Ge, B. Zheng, Q. Wang, Adversarial network pruning by filter\\nrobustness estimation, in: ICASSP 2023-2023 IEEE International Conference on\\nAcoustics, Speech and Signal Processing (ICASSP), IEEE, 2023, pp. 1–5.',\n",
       " 'Reference [14]: Z. Liu, M. Sun, T. Zhou, G. Huang, T. Darrell, Rethinking the value of network\\npruning, in: International Conference on Learning Representations (ICLR), 2019.',\n",
       " 'Reference [15]: Y. Li, K. Adamczewski, W. Li, S. Gu, R. Timofte, L. Van Gool, Revisiting\\nrandom channel pruning for neural network compression, in: Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp.\\n191–201.',\n",
       " 'Reference [16]: Y. Li, P. Zhao, G. Yuan, X. Lin, Y. Wang, X. Chen, Pruning-as-search: Efficient\\nneural architecture search via channel pruning and structural reparameterization,\\nin: Proceedings of the Thirty-First International Joint Conference on Artificial\\nIntelligence, 2022, pp. 3236–3242.',\n",
       " 'Reference [17]: Y. Ding, Y. Wu, C. Huang, S. Tang, F. Wu, Y. Yang, W. Zhu, Y. Zhuang, NAP:\\n\\nNeural architecture search with pruning, Neurocomputing 477 (2022) 85–95.',\n",
       " 'Reference [18]: S. Teerapittayanon, B. McDanel, H.-T. Kung, Branchynet: Fast inference via early\\nexiting from deep neural networks, in: 2016 23rd International Conference on\\nPattern Recognition (ICPR), IEEE, 2016, pp. 2464–2469.',\n",
       " 'Reference [19]: P. Panda, A. Sengupta, K. Roy, Conditional deep learning for energy-efficient\\nand enhanced pattern recognition, in: 2016 Design, Automation & Test in Europe\\nConference & Exhibition (DATE), IEEE, 2016, pp. 475–480.',\n",
       " 'Reference [20]: Y. Yang, D. Liu, H. Fang, Y.-X. Huang, Y. Sun, Z.-Y. Zhang, Once for all skip:\\nefficient adaptive deep neural networks, in: 2022 Design, Automation & Test in\\nEurope Conference & Exhibition (DATE), IEEE, 2022, pp. 568–571.',\n",
       " 'Reference [21]: B. Fang, X. Zeng, F. Zhang, H. Xu, M. Zhang, FlexDNN: Input-adaptive on-device\\ndeep learning for efficient mobile vision, in: 2020 IEEE/ACM Symposium on Edge\\nComputing (SEC), IEEE, 2020, pp. 84–95.',\n",
       " 'Reference [22]: Y. Wang, J. Shen, T.-K. Hu, P. Xu, T. Nguyen, R. Baraniuk, Z. Wang, Y. Lin,\\nDual dynamic inference: Enabling more efficient, adaptive, and controllable deep\\ninference, IEEE J. Sel. Top. Sign. Proces. 14 (4) (2020) 623–633.',\n",
       " 'Reference [23]: M. Figurnov, M.D. Collins, Y. Zhu, L. Zhang, J. Huang, D. Vetrov, R. Salakhutdi-\\nnov, Spatially adaptive computation time for residual networks, in: Proceedings\\nof the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp.\\n1039–1048.',\n",
       " 'Reference [24]: N.K. Jayakodi, A. Chatterjee, W. Choi, J.R. Doppa, P.P. Pande, Trading-off\\naccuracy and energy of deep inference on embedded systems: A co-design\\napproach, IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst. 37 (11) (2018)\\n2881–2893.',\n",
       " 'Reference [25]: Z. Liang, Y. Zhou, Dispense mode for inference to accelerate branchynet, in:\\n2022 IEEE International Conference on Image Processing (ICIP), IEEE, 2022, pp.\\n1246–1250.',\n",
       " 'Reference [26]: J. Jo, G. Kim, S. Kim, J. Park, LoCoExNet: Low-cost early exit network for energy\\nefficient CNN accelerator design, IEEE Trans. Comput.-Aided Des. Integr. Circuits\\nSyst. (2023).',\n",
       " 'Reference [27]: K. Park, C. Oh, Y. Yi, Bpnet: branch-pruned conditional neural network for\\nsystematic time-accuracy tradeoff, in: 2020 57th ACM/IEEE Design Automation\\nConference (DAC), IEEE, 2020, pp. 1–6.',\n",
       " 'Reference [28]: G. Park, Y. Yi, Condnas: neural architecture search for conditional CNNs,\\n\\nElectronics 11 (7) (2022) 1101.',\n",
       " 'Reference [29]: Y. He, J. Lin, Z. Liu, H. Wang, L.-J. Li, S. Han, Amc: Automl for model\\ncompression and acceleration on mobile devices, in: Proceedings of the European\\nConference on Computer Vision (ECCV), 2018, pp. 784–800.',\n",
       " 'Reference [30]: Y. Qian, Z. He, Y. Wang, B. Wang, X. Ling, Z. Gu, H. Wang, S. Zeng, W. Swaileh,\\nHierarchical threshold pruning based on uniform response criterion, IEEE Trans.\\nNeural Netw. Learn. Syst. (2023).',\n",
       " 'Reference [31]: K. Wang, D. Zhang, Y. Li, R. Zhang, L. Lin, Cost-effective active learning for deep\\nimage classification, IEEE Trans. Circuits Syst. Video Technol. 27 (12) (2016)\\n2591–2600.',\n",
       " 'Reference [32]: S. Anwar, K. Hwang, W. Sung, Structured pruning of deep convolutional neural\\n\\nnetworks, ACM J. Emerg. Technol. Comput. Syst. (JETC) 13 (3) (2017) 1–18.',\n",
       " 'Reference [33]: J.H. Holland, Adaptation in Natural and Artificial Systems: An Introductory\\nAnalysis with Applications To Biology, Control, and Artificial Intelligence, MIT\\nPress, 1992.',\n",
       " 'Reference [34]: A. Mohammadi, H. Asadi, S. Mohamed, K. Nelson, S. Nahavandi, OpenGA, a C++\\ngenetic algorithm library, in: 2017 IEEE International Conference on Systems,\\nMan, and Cybernetics (SMC), IEEE, 2017, pp. 2051–2056.',\n",
       " 'Reference [35]: K. Deb, H. Jain, An evolutionary many-objective optimization algorithm using\\nreference-point-based nondominated sorting approach, part I: solving problems\\nwith box constraints, IEEE Trans. Evol. Comput. 18 (4) (2013) 577–601.',\n",
       " 'Reference [36]: A. Krizhevsky, G. Hinton, et al., Learning multiple layers of features from tiny\\n\\nimages, 2009.',\n",
       " 'Reference [37]: L.N. Darlow, E.J. Crowley, A. Antoniou, A.J. Storkey, Cinic-10 is not imagenet\\n\\nor cifar-10, 2018, arXiv preprint arXiv:1810.03505.',\n",
       " 'Reference [38]: L. Cai, Z. An, C. Yang, Y. Xu, Softer pruning, incremental regularization, in:\\n2020 25th International Conference on Pattern Recognition (ICPR), IEEE, 2021,\\npp. 224–230.',\n",
       " 'Reference [39]: X. Dong, J. Huang, Y. Yang, S. Yan, More is less: A more complicated network\\nin: Proceedings of the IEEE Conference on\\n\\nwith less inference complexity,\\nComputer Vision and Pattern Recognition, 2017, pp. 5840–5848.',\n",
       " 'Reference [40]: Y. He, P. Liu, Z. Wang, Z. Hu, Y. Yang, Filter pruning via geometric median\\nfor deep convolutional neural networks acceleration,\\nin: Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp.\\n4340–4349.',\n",
       " 'Reference [41]: X. Dong, Y. Yang, Network pruning via transformable architecture search, Adv.\\n\\nNeural Inf. Process. Syst. 32 (2019).',\n",
       " 'Reference [42]: Y. He, X. Zhang, J. Sun, Channel pruning for accelerating very deep neural\\nnetworks, in: Proceedings of the IEEE International Conference on Computer\\nVision, 2017, pp. 1389–1397.',\n",
       " 'Reference [43]: S. Lin, R. Ji, C. Yan, B. Zhang, L. Cao, Q. Ye, F. Huang, D. Doermann,\\nTowards optimal structured cnn pruning via generative adversarial\\nlearning,\\nin: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, 2019, pp. 2790–2799.',\n",
       " 'Reference [44]: L. Cai, Z. An, C. Yang, Y. Xu, Soft and hard filter pruning via dimension\\nreduction, in: 2021 International Joint Conference on Neural Networks (IJCNN),\\nIEEE, 2021, pp. 1–8.',\n",
       " 'Reference [45]: X. Yang, H. Lu, H. Shuai, X.-T. Yuan, Pruning convolutional neural networks\\nvia stochastic gradient hard thresholding, in: Pattern Recognition and Computer\\nVision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11,\\n2019, Proceedings, Part I, Springer, 2019, pp. 373–385.',\n",
       " 'Reference [46]: O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A.\\nKarpathy, A. Khosla, M. Bernstein, et al., Imagenet large scale visual recognition\\nchallenge, Int. J. Comput. Vis. 115 (3) (2015) 211–252.',\n",
       " 'Reference [47]: Y. Chen, X. Wen, Y. Zhang, Q. He, FPC: Filter pruning via the contribution\\nof output feature map for deep convolutional neural networks acceleration,\\nKnowl.-Based Syst. 238 (2022) 107876.',\n",
       " 'Reference [48]: Y. Chen, X. Wen, Y. Zhang, W. Shi, CCPrune: Collaborative channel pruning for\\n\\nlearning compact convolutional networks, Neurocomputing 451 (2021) 35–45.',\n",
       " 'Reference [49]: X. Chen, H. Ma, J. Wan, B. Li, T. Xia, Multi-view 3d object detection network\\nfor autonomous driving, in: Proceedings of the IEEE Conference on Computer\\nVision and Pattern Recognition, 2017, pp. 1907–1915.',\n",
       " 'Reference [50]: G. Hinton, O. Vinyals, J. Dean, et al., Distilling the knowledge in a neural\\n\\nnetwork, arXiv preprint arXiv:1503.02531 2 (7) (2015).',\n",
       " 'Reference [51]: J. Horn, N. Nafpliotis, D.E. Goldberg, Multiobjective optimization using the\\n\\nniched Pareto genetic algorithm, 1993']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ref_pattern = r'\\[\\d+\\]'\n",
    "split = re.split(ref_pattern, references_text)\n",
    "references_list = split[1:-1] + [split[-1].split('.\\n')[0]]\n",
    "references_list = [r.strip() for r in references_list]\n",
    "references_list = [f\"Reference [{i+1}]: \"+r for i, r in enumerate(references_list)]\n",
    "references_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reference [51]: J. Horn, N. Nafpliotis, D.E. Goldberg, Multiobjective optimization using the\\n\\nniched Pareto genetic algorithm, 1993'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68422"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "Fem6SSK7u8Cp"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap  = 300,\n",
    "    separators = [\"\\n\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "_-AhB_DGvQp0"
   },
   "outputs": [],
   "source": [
    "splits = text_splitter.split_text(paper_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMr_BcmTvL6q",
    "outputId": "c9af435d-b70f-456c-ca44-e3c239983954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contents lists available at ScienceDirect\\n\\nJournal of Systems Architecture\\n\\njournal homepage: www.elsevier.com/locate/sysarc\\n\\nCoAxNN: Optimizing on-device deep learning with conditional approximate\\nneural networks\\nGuangli Li a,b,1, Xiu Ma c,d,1, Qiuchu Yu a,b, Lei Liu c,d, Huaxiao Liu c,d, Xueying Wang a,b,∗\\na State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China\\nb University of Chinese Academy of Sciences, Beijing, China\\nc College of Computer Science and Technology, Jilin University, Changchun, China\\nd MOE Key Laboratory of Symbolic Computation and Knowledge Engineering, Jilin University, Changchun, China\\n\\nA R T I C L E I N F O\\n\\nA B S T R A C T\\n\\nKeywords:\\nOn-device deep learning\\nEfficient neural networks\\nModel approximation and optimization\\n\\nWhile deep neural networks have achieved superior performance in a variety of intelligent applications, the\\nincreasing computational complexity makes them difficult to be deployed on resource-constrained devices. To'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Efficient neural networks\\nModel approximation and optimization\\n\\nWhile deep neural networks have achieved superior performance in a variety of intelligent applications, the\\nincreasing computational complexity makes them difficult to be deployed on resource-constrained devices. To\\nimprove the performance of on-device inference, prior studies have explored various approximate strategies,\\nsuch as neural network pruning, to optimize models based on different principles. However, when combining\\nthese approximate strategies, a large parameter space needs to be explored. Meanwhile, different configuration\\nparameters may interfere with each other, damaging the performance optimization effect. In this paper, we\\npropose a novel model optimization framework, CoAxNN, which effectively combines different approximate\\nstrategies, to facilitate on-device deep learning via model approximation. Based on the principles of different'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n",
      "1022\n",
      "1023\n",
      "1021\n",
      "1020\n",
      "1020\n",
      "1022\n",
      "1022\n"
     ]
    }
   ],
   "source": [
    "for s in splits:\n",
    "    ls = len(s)\n",
    "    if ls >= 1020:\n",
    "        print(ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "Q5H2AHi3S7H5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([split for split in splits] + references_list, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GefSHuVvTED_",
    "outputId": "d4be44b8-d13b-4931-826e-57b510f53aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 1)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    motivation are introduced in Section 2. The de...\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2UA4pgUQTE6j",
    "outputId": "ac7c8858-5a27-4361-be3e-3eb74e947211"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contents lists available at ScienceDirect\\n\\nJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efficient neural networks\\nModel approximation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>propose a novel model optimization framework, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>up to 1.53× speedup while reducing energy by u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to the limited resources.\\n\\nMany efforts have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Contents lists available at ScienceDirect\\n\\nJ...\n",
       "1  Efficient neural networks\\nModel approximation...\n",
       "2  propose a novel model optimization framework, ...\n",
       "3  up to 1.53× speedup while reducing energy by u...\n",
       "4  to the limited resources.\\n\\nMany efforts have..."
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reference [42]: Y. He, X. Zhang, J. Sun, Channel pruning for accelerating very deep neural\\nnetworks, in: Proceedings of the IEEE International Conference on Computer\\nVision, 2017, pp. 1389–1397.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "B9lgulVpSPyd"
   },
   "outputs": [],
   "source": [
    "df.to_csv(csv_putput_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "RPouJr1iTRUY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_coaxnn_paper.csv'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_putput_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________\n",
      "Contents lists available at ScienceDirect\n",
      "\n",
      "Journal of Systems Architecture\n",
      "\n",
      "journal homepage: www.elsevier.com/locate/sysarc\n",
      "\n",
      "CoAxNN: Optimizing on-device deep learning with conditional approximate\n",
      "neural networks\n",
      "Guangli Li a,b,1, Xiu Ma c,d,1, Qiuchu Yu a,b, Lei Liu c,d, Huaxiao Liu c,d, Xueying Wang a,b,∗\n",
      "a State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China\n",
      "b University of Chinese Academy of Sciences, Beijing, China\n",
      "c College of Computer Science and Technology, Jilin University, Changchun, China\n",
      "d MOE Key Laboratory of Symbolic Computation and Knowledge Engineering, Jilin University, Changchun, China\n",
      "\n",
      "A R T I C L E I N F O\n",
      "\n",
      "A B S T R A C T\n",
      "\n",
      "Keywords:\n",
      "On-device deep learning\n",
      "Efficient neural networks\n",
      "Model approximation and optimization\n",
      "\n",
      "While deep neural networks have achieved superior performance in a variety of intelligent applications, the\n",
      "increasing computational complexity makes them difficult to be deployed on resource-constrained devices. To______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Efficient neural networks\n",
      "Model approximation and optimization\n",
      "\n",
      "While deep neural networks have achieved superior performance in a variety of intelligent applications, the\n",
      "increasing computational complexity makes them difficult to be deployed on resource-constrained devices. To\n",
      "improve the performance of on-device inference, prior studies have explored various approximate strategies,\n",
      "such as neural network pruning, to optimize models based on different principles. However, when combining\n",
      "these approximate strategies, a large parameter space needs to be explored. Meanwhile, different configuration\n",
      "parameters may interfere with each other, damaging the performance optimization effect. In this paper, we\n",
      "propose a novel model optimization framework, CoAxNN, which effectively combines different approximate\n",
      "strategies, to facilitate on-device deep learning via model approximation. Based on the principles of different______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "propose a novel model optimization framework, CoAxNN, which effectively combines different approximate\n",
      "strategies, to facilitate on-device deep learning via model approximation. Based on the principles of different\n",
      "approximate optimizations, our approach constructs the design space and automatically finds reasonable\n",
      "configurations through genetic algorithm-based design space exploration. By combining the strengths of\n",
      "different approximation methods, CoAxNN enables efficient conditional inference for models at runtime. We\n",
      "evaluate our approach by leveraging state-of-the-art neural networks on a representative intelligent edge\n",
      "platform, Jetson AGX Orin. The experimental results demonstrate the effectiveness of CoAxNN, which achieves\n",
      "up to 1.53× speedup while reducing energy by up to 34.61%, with trivial accuracy loss on CIFAR-10/100 and\n",
      "CINIC-10 datasets.\n",
      "\n",
      "1. Introduction\n",
      "\n",
      "Convolutional neural networks (CNNs) have achieved remarkable\n",
      "success in various intelligent tasks such as image classification [1].______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "up to 1.53× speedup while reducing energy by up to 34.61%, with trivial accuracy loss on CIFAR-10/100 and\n",
      "CINIC-10 datasets.\n",
      "\n",
      "1. Introduction\n",
      "\n",
      "Convolutional neural networks (CNNs) have achieved remarkable\n",
      "success in various intelligent tasks such as image classification [1].\n",
      "To pursue superior performance on complex intelligent tasks, CNNs\n",
      "are becoming wider and deeper, leading to tremendous computational\n",
      "costs and expensive energy consumption for model execution. Recently,\n",
      "on-device deep learning has been a mainstay due to its immeasurable\n",
      "potential for privacy protection and real-time response. However, it is\n",
      "hard to deploy complicated neural network models on edge devices due\n",
      "to the limited resources.\n",
      "\n",
      "Many efforts have been made to enable efficient on-device deep\n",
      "learning via model approximation. For instance, pruning-based strate-\n",
      "gies [2] compress a neural network model by reducing redundant\n",
      "neurons and connections and quantization-based methods [3] improve______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "to the limited resources.\n",
      "\n",
      "Many efforts have been made to enable efficient on-device deep\n",
      "learning via model approximation. For instance, pruning-based strate-\n",
      "gies [2] compress a neural network model by reducing redundant\n",
      "neurons and connections and quantization-based methods [3] improve\n",
      "\n",
      "the efficiency of model execution by leveraging low-precision compu-\n",
      "tations. In addition to these model compression techniques, emerging\n",
      "staging-based approximate strategies, such as early exiting, improve\n",
      "model performance by conditional execution at runtime.\n",
      "\n",
      "While these methods optimize the deep neural network models from\n",
      "different directions, we found that it is still a challenging problem\n",
      "to effectively combine them (as described in Section 2.4). To achieve\n",
      "efficient on-device inference, it is needed to take full advantage of the\n",
      "superiority of different optimization strategies. Different approximate\n",
      "strategies, based on distinct principles, have their own configuration______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "to effectively combine them (as described in Section 2.4). To achieve\n",
      "efficient on-device inference, it is needed to take full advantage of the\n",
      "superiority of different optimization strategies. Different approximate\n",
      "strategies, based on distinct principles, have their own configuration\n",
      "parameters. When combining different strategies, the configuration\n",
      "parameters of different strategies may affect each other, influencing the\n",
      "optimization effect of the model, and even leading to poor optimization\n",
      "results. As such, this paper aims to address the following challenging\n",
      "problem: How to design an efficient model optimization framework to make\n",
      "\n",
      "∗ Corresponding author at: State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China.\n",
      "\n",
      "E-mail addresses:\n",
      "\n",
      "liguangli@ict.ac.cn (G. Li), maxiu18@mails.jlu.edu.cn (X. Ma), yuqiuchu19@mails.ucas.ac.cn (Q. Yu), liulei@jlu.edu.cn (L. Liu),\n",
      "\n",
      "liuhuaxiao@jlu.edu.cn (H. Liu), wangxueying@ict.ac.cn (X. Wang).______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "E-mail addresses:\n",
      "\n",
      "liguangli@ict.ac.cn (G. Li), maxiu18@mails.jlu.edu.cn (X. Ma), yuqiuchu19@mails.ucas.ac.cn (Q. Yu), liulei@jlu.edu.cn (L. Liu),\n",
      "\n",
      "liuhuaxiao@jlu.edu.cn (H. Liu), wangxueying@ict.ac.cn (X. Wang).\n",
      "\n",
      "1 Guangli Li and Xiu Ma contributed equally to this work.\n",
      "\n",
      "https://doi.org/10.1016/j.sysarc.2023.102978\n",
      "Received 24 April 2023; Received in revised form 18 July 2023; Accepted 23 August 2023\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)102978Availableonline25August20231383-7621/©2023ElsevierB.V.Allrightsreserved.\f\n",
      "G. Li et al.\n",
      "\n",
      "full use of various model approximate strategies, so as to optimize on-device\n",
      "deep learning while meeting accuracy requirements?\n",
      "\n",
      "In this paper, we present a novel neural network optimization\n",
      "framework, CoAxNN (Conditional Approximate Neural Networks),\n",
      "which effectively combines staging-based and pruning-based approx-\n",
      "imate strategies, for efficient on-device deep learning. The staging-\n",
      "based approximate strategy optimizes the model structure as multiple______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "framework, CoAxNN (Conditional Approximate Neural Networks),\n",
      "which effectively combines staging-based and pruning-based approx-\n",
      "imate strategies, for efficient on-device deep learning. The staging-\n",
      "based approximate strategy optimizes the model structure as multiple\n",
      "stages with different complexities by attaching multiple exit branches,\n",
      "whereas the pruning-based approximate strategy compresses the model\n",
      "parameters according to the importance of filters. CoAxNN takes ac-\n",
      "count of both their optimization principles and automatically searches\n",
      "for reasonable configuration parameters to construct a compressed\n",
      "multi-stage neural network model, thus taking full advantage of the\n",
      "superiority of different approximate strategies to achieve efficient\n",
      "model optimization. The optimization techniques, including pruning\n",
      "and staging, have been studied individually in the past; the key novelty\n",
      "of our work is to provide an effective and efficient mechanism to\n",
      "combine them, so as to optimize the neural network performance with______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "model optimization. The optimization techniques, including pruning\n",
      "and staging, have been studied individually in the past; the key novelty\n",
      "of our work is to provide an effective and efficient mechanism to\n",
      "combine them, so as to optimize the neural network performance with\n",
      "a reasonable configuration, for a given task and a platform.\n",
      "The main contributions of this paper are as follows:\n",
      "\n",
      "• We present a novel neural network optimization framework,\n",
      "namely CoAxNN, which effectively combines staging-based and\n",
      "pruning-based approximate strategies, thereby improving actual\n",
      "performance while meeting accuracy requirements, for efficient\n",
      "on-device model inference.\n",
      "\n",
      "• According to the principles of staging-based and pruning-based\n",
      "approximate strategies, our framework constructs the design\n",
      "space, and automatically searches for reasonable configuration\n",
      "parameters, including the number of stages, the position of stages,\n",
      "the threshold of stages, and the pruning rate, so as to make______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "approximate strategies, our framework constructs the design\n",
      "space, and automatically searches for reasonable configuration\n",
      "parameters, including the number of stages, the position of stages,\n",
      "the threshold of stages, and the pruning rate, so as to make\n",
      "full use of the advantages of both to achieve efficient model\n",
      "optimization.\n",
      "\n",
      "• We validate the effectiveness of CoAxNN by optimizing state-of-\n",
      "the-art deep neural networks on a commercial edge device, Jetson\n",
      "AGX Orin, in terms of prediction accuracy, execution latency, and\n",
      "energy consumption, and experimental results show that CoAxNN\n",
      "can significantly improve the performance of model inference\n",
      "with trivial accuracy loss.\n",
      "\n",
      "The rest of the paper is organized as follows. The background and\n",
      "motivation are introduced in Section 2. The details of our optimization\n",
      "framework are described in Section 3. The experimental evaluation\n",
      "is conducted in Section 4. A discussion is given in Section 5. The\n",
      "conclusion is presented in Section 6.\n",
      "\n",
      "2. Background and motivation______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "motivation are introduced in Section 2. The details of our optimization\n",
      "framework are described in Section 3. The experimental evaluation\n",
      "is conducted in Section 4. A discussion is given in Section 5. The\n",
      "conclusion is presented in Section 6.\n",
      "\n",
      "2. Background and motivation\n",
      "\n",
      "2.1. Pruning-based approximation\n",
      "\n",
      "Neural network pruning, one of the most representative model com-\n",
      "pression techniques, approximates the original neural network model\n",
      "by reducing redundant neurons or connections making less contribu-\n",
      "tion to model performance. Most previous works on pruning-based\n",
      "approximation can be roughly divided into two categories: unstructured\n",
      "pruning and structured pruning.\n",
      "\n",
      "Prior works on weight pruning [4,5] achieve high non-structured\n",
      "sparsity of pruned models by removing single parameters in a fil-\n",
      "ter. Guo et al. [4] and Hal et al. [5] used magnitude-based pruning\n",
      "methods, which eliminate weights with the smallest magnitude. Guo\n",
      "et al. [4] proposed dynamic network surgery to reduce the network______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "sparsity of pruned models by removing single parameters in a fil-\n",
      "ter. Guo et al. [4] and Hal et al. [5] used magnitude-based pruning\n",
      "methods, which eliminate weights with the smallest magnitude. Guo\n",
      "et al. [4] proposed dynamic network surgery to reduce the network\n",
      "complexity by making on-the-fly connection pruning. Hal et al. [5]\n",
      "pruned low-weight connections to reduce the storage and computation\n",
      "demands by an order of magnitude. Some pruning research groups\n",
      "utilize first-order or second-order derivatives of the loss function with\n",
      "respect to the weights [6,7]. Hassibi et al. [6] proposed Optimal Brain\n",
      "Damage (OBD), which uses all second-order derivatives of the loss\n",
      "\n",
      "function to prune single non-essential weights. Optimal Brain Surgeon\n",
      "(OBS) [7] have optimized the OBD method, which considers the condi-\n",
      "tion that the Hessian matrix is non-diagonal. These approaches show\n",
      "attractive theoretical performance improvement but are difficult to\n",
      "be supported by existing software and hardware. Unstructured sparse______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "(OBS) [7] have optimized the OBD method, which considers the condi-\n",
      "tion that the Hessian matrix is non-diagonal. These approaches show\n",
      "attractive theoretical performance improvement but are difficult to\n",
      "be supported by existing software and hardware. Unstructured sparse\n",
      "models require specific matrix multiplication calculations and stor-\n",
      "age formats, which can hardly leverage existing high-efficiency BLAS\n",
      "libraries.\n",
      "\n",
      "Unlike the early efforts on unstructured pruning that may cause\n",
      "irregular calculation patterns, structured pruning reduces redundant\n",
      "computations on unimportant filters or channels to produce a struc-\n",
      "tured sparse model. The corresponding feature maps can be deleted as\n",
      "the filters are pruned. Therefore, much recent work has focused on filter\n",
      "pruning methods. SFP [2] and ASFP [8] dynamically pruned the filters\n",
      "in a soft manner, which zeroizes the unimportant filters and keeps\n",
      "updating them in the training stage. Li et al. [9] presented a fusion-______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "the filters are pruned. Therefore, much recent work has focused on filter\n",
      "pruning methods. SFP [2] and ASFP [8] dynamically pruned the filters\n",
      "in a soft manner, which zeroizes the unimportant filters and keeps\n",
      "updating them in the training stage. Li et al. [9] presented a fusion-\n",
      "catalyzed filter pruning approach, which simultaneously optimizes the\n",
      "parametric and non-parametric operators. Luo et al. [10] pruned filters\n",
      "based on statistics information computed from its next layer. The filters\n",
      "of different layers may have different influences on model prediction. Li\n",
      "et al. [11] proposed a flexible-rate filter pruning approach, FlexPruner,\n",
      "which automatically selects the number of filters to be pruned for\n",
      "each layer. Plochaet et al. [12] introduced a hardware-aware pruning\n",
      "method with the goal of decreasing the inference time for FPGA deep\n",
      "learning accelerators, adaptively pruning the neural network based on\n",
      "the size of the systolic array used to calculate the convolutions. To______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "each layer. Plochaet et al. [12] introduced a hardware-aware pruning\n",
      "method with the goal of decreasing the inference time for FPGA deep\n",
      "learning accelerators, adaptively pruning the neural network based on\n",
      "the size of the systolic array used to calculate the convolutions. To\n",
      "preserve the robustness at a high sparsity ratio in structured pruning,\n",
      "Zhuang et al. [13] proposed an effective filter importance criterion to\n",
      "evaluate the importance of filters by estimating their contribution to\n",
      "the adversarial training loss. Besides, some researchers have found\n",
      "the value of network pruning in discovering the network architecture\n",
      "[14,15]. Liu et al. [14] demonstrated that in some cases pruning can\n",
      "be useful as an architecture search paradigm. Li et al. [15] proposed\n",
      "a random architecture search to find a good architecture given a\n",
      "pre-defined model by channel pruning. Li et al. [16] proposed an end-\n",
      "to-end channel pruning method to search out the desired sub-network______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "be useful as an architecture search paradigm. Li et al. [15] proposed\n",
      "a random architecture search to find a good architecture given a\n",
      "pre-defined model by channel pruning. Li et al. [16] proposed an end-\n",
      "to-end channel pruning method to search out the desired sub-network\n",
      "automatically and efficiently, which learns per-layer sparsity through\n",
      "depth-wise binary convolution. Ding et al. [17] presented a neural\n",
      "architecture search with pruning method, which derives the most po-\n",
      "tent model by removing trivial and redundant edges from the whole\n",
      "neural network topology. The structured sparse model can be perfectly\n",
      "supported by existing libraries to achieve a realistic acceleration. In\n",
      "this paper, we adopt filter pruning to realize practical performance\n",
      "improvement for neural network models.\n",
      "\n",
      "2.2. Staging-based approximation\n",
      "\n",
      "Prior studies [18,19] found that the difficulty of classifying an image\n",
      "in real-world scenarios is diverse. The easy samples can be classified______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "this paper, we adopt filter pruning to realize practical performance\n",
      "improvement for neural network models.\n",
      "\n",
      "2.2. Staging-based approximation\n",
      "\n",
      "Prior studies [18,19] found that the difficulty of classifying an image\n",
      "in real-world scenarios is diverse. The easy samples can be classified\n",
      "with low effort, and difficult samples consume more computation ef-\n",
      "forts for prediction. Staging-based approximate strategies, such as early\n",
      "exiting [18] and layer skipping [20], emerge as a prominent important\n",
      "technique for separating the classification of easy and hard inputs.\n",
      "The original neural network uses a fixed computation process for the\n",
      "prediction of all samples. Staging-based approximate strategies perform\n",
      "adaptive computing for samples according to conditions at run-time.\n",
      "Teerapittayanon et al. [18] demonstrated that the deep neural network\n",
      "with additional side branch classifiers can both improve accuracy and\n",
      "significantly reduce the inference time of the network. Panda et al. [19]______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "adaptive computing for samples according to conditions at run-time.\n",
      "Teerapittayanon et al. [18] demonstrated that the deep neural network\n",
      "with additional side branch classifiers can both improve accuracy and\n",
      "significantly reduce the inference time of the network. Panda et al. [19]\n",
      "proposed Conditional Deep Learning cascading a linear network for\n",
      "each convolutional layer and monitoring the output of the linear net-\n",
      "work to decide whether classification can be terminated at the current\n",
      "stage or not. Fang et al. [21] presented an input-adaptive framework\n",
      "for video analytics, which adopts an architecture search-based scheme\n",
      "to find the optimal architecture for each early exit branch. Wang\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029782\f\n",
      "G. Li et al.\n",
      "\n",
      "et al. [22] designed dynamic layer-skipping mechanisms, which sup-\n",
      "press unnecessary costs for easy samples and halt inference for all\n",
      "samples to meet resource constraints for the inference of more compli-______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "JournalofSystemsArchitecture143(2023)1029782\f\n",
      "G. Li et al.\n",
      "\n",
      "et al. [22] designed dynamic layer-skipping mechanisms, which sup-\n",
      "press unnecessary costs for easy samples and halt inference for all\n",
      "samples to meet resource constraints for the inference of more compli-\n",
      "cated CNN backbones. Figurnov et al. [23] studied early termination in\n",
      "each residual unit of ResNets. Farhadi et al. [23] implemented an early-\n",
      "exiting method on the FPGA platform using partial reconfiguration to\n",
      "reduce the amount of needed computation. Jayakodi et al. [24] used\n",
      "Bayesian Optimization to configure the early exit neural networks to\n",
      "trade off accuracy and energy. To reduce unnecessary intermediate\n",
      "calculations in the inference process of Branchynet, Liang et al. [25]\n",
      "directly determined the exit position of the sample in the multi-branch\n",
      "network according to the difficulty of the sample without intermediate\n",
      "trial errors. Jo et al. [26] proposed a low-cost early exit network, which______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "calculations in the inference process of Branchynet, Liang et al. [25]\n",
      "directly determined the exit position of the sample in the multi-branch\n",
      "network according to the difficulty of the sample without intermediate\n",
      "trial errors. Jo et al. [26] proposed a low-cost early exit network, which\n",
      "significantly improves energy efficiencies by reducing the parameters\n",
      "used in inference with efficient branch structures.\n",
      "In this paper, we\n",
      "achieve a multi-stage approximate model by early exiting to accelerate\n",
      "model inference for input samples in real-world scenarios.\n",
      "\n",
      "2.3. Design space exploration\n",
      "\n",
      "Design space exploration (DSE) is a systematic analysis method,\n",
      "which searches for the optimal solutions in a large design space accord-\n",
      "ing to the requirements. For example, in the staging-based approximate\n",
      "strategy, deciding whether or not an exit branch should be inserted at\n",
      "some position in the middle of the neural network model, and how\n",
      "the thresholds for each exit point should be set can be seen as a DSE______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "ing to the requirements. For example, in the staging-based approximate\n",
      "strategy, deciding whether or not an exit branch should be inserted at\n",
      "some position in the middle of the neural network model, and how\n",
      "the thresholds for each exit point should be set can be seen as a DSE\n",
      "problem. Panda et al. [19] and Teerapittayanon et al. [18] empirically\n",
      "set the location and threshold for each exit in the conditional neural\n",
      "network model. Jayakodi et al. [24] found the best thresholds via\n",
      "Bayesian Optimization for the specified trade-off between accuracy\n",
      "and energy consumption of inference. Park et al. [27] systematically\n",
      "determined the locations and thresholds of exit branches by genetic\n",
      "algorithm. Park et al. [28] integrated the once-for-all technique and\n",
      "BPNet, which consider architectures of base network and exit branches\n",
      "simultaneously in the same search process. Besides, the fine-grained fil-\n",
      "ter pruning, that is assign reasonable pruning rates for different layers,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "algorithm. Park et al. [28] integrated the once-for-all technique and\n",
      "BPNet, which consider architectures of base network and exit branches\n",
      "simultaneously in the same search process. Besides, the fine-grained fil-\n",
      "ter pruning, that is assign reasonable pruning rates for different layers,\n",
      "can also be considered as a classic DSE problem. Li et al. [11] proposed\n",
      "a flexible-rate filter pruning method, which selects the filters to be\n",
      "pruned with a greedy-based strategy. He et al. [29] sampled design\n",
      "space using reinforcement learning, which performs customizing prun-\n",
      "ing for each layer, thus improving model compression. Qian et al. [30]\n",
      "proposed a hierarchical threshold pruning method, which considers\n",
      "the filter importance within relatively redundant layers instead of all\n",
      "layers, achieving layerwise pruning for a better network structure. In\n",
      "this paper, we regard the configuration parameters of staging-based\n",
      "and pruning-based approximate strategies as the whole design space______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "the filter importance within relatively redundant layers instead of all\n",
      "layers, achieving layerwise pruning for a better network structure. In\n",
      "this paper, we regard the configuration parameters of staging-based\n",
      "and pruning-based approximate strategies as the whole design space\n",
      "and employ a genetic algorithm(GA)-based DSE to automatically find\n",
      "the (near-)optimal configuration to effectively combine them, achieving\n",
      "efficient on-device inference. In the future, we will consider setting\n",
      "reasonable pruning rates for different layers.\n",
      "\n",
      "2.4. Motivation\n",
      "\n",
      "The pruning-based approximate strategy focuses on compressing the\n",
      "model, which reduces the computation costs by deleting unimportant\n",
      "parameters in the model, so how to set the pruning rate needs to be\n",
      "considered. The staging-based approximate strategy concentrates on\n",
      "improving the execution speed of the model, which allows the inference\n",
      "of most simple samples to terminate with a good prediction in the______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "parameters in the model, so how to set the pruning rate needs to be\n",
      "considered. The staging-based approximate strategy concentrates on\n",
      "improving the execution speed of the model, which allows the inference\n",
      "of most simple samples to terminate with a good prediction in the\n",
      "earlier stage by attaching multiple exits in the original model. How\n",
      "to place the exits and how to set a threshold for each exit should\n",
      "be considered for the design of a staging-based approximate strategy.\n",
      "Combining different approximate strategies will involve more configu-\n",
      "ration parameters and the approximate strategies may affect each other,\n",
      "which potentially influences the effect of the model optimization.\n",
      "\n",
      "Fig. 1. The optimization effect for ResNet-56 using different configuration parameters\n",
      "under the specified accuracy requirement.\n",
      "\n",
      "Fig. 1 shows the optimization effect of the ResNet-56 using different\n",
      "configuration parameters under the specified requirements of accuracy______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Fig. 1. The optimization effect for ResNet-56 using different configuration parameters\n",
      "under the specified accuracy requirement.\n",
      "\n",
      "Fig. 1 shows the optimization effect of the ResNet-56 using different\n",
      "configuration parameters under the specified requirements of accuracy\n",
      "on the CIFAR-10 dataset, where the triples (𝑥, 𝑦, 𝑧) represent the number\n",
      "of stages, stage threshold, and pruning rate, respectively. Fig. 1(a), (b),\n",
      "and (c) show the computational costs (normalized to the computational\n",
      "cost of the baseline model) of various optimization configurations\n",
      "when the accuracy is 98.1%, 98.7%, and 98.8% (normalized to the\n",
      "accuracy of the baseline model). In practice, a certain error can be\n",
      "allowed in model accuracy (±0.001), for example, 98.09%, and 98.12%\n",
      "both meet the requirement of 98.1%. The relationship between the\n",
      "number of stages and the computational cost is not regular, which\n",
      "will be affected by the stage threshold and pruning rate, for example,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "allowed in model accuracy (±0.001), for example, 98.09%, and 98.12%\n",
      "both meet the requirement of 98.1%. The relationship between the\n",
      "number of stages and the computational cost is not regular, which\n",
      "will be affected by the stage threshold and pruning rate, for example,\n",
      "in Fig. 1(c), the computational cost of (3,0.08,0) with more stages is\n",
      "larger than (2,0.1,0.1), the computational cost of (2,0.1,0.1) with fewer\n",
      "stages is larger than (3,0.2,0.1). Besides, affected by the staging-based\n",
      "optimization, the computational costs of the optimized model at a high\n",
      "pruning rate may be larger than that at low pruning rates, for example,\n",
      "in Fig. 1(b), the configuration of (2,0.08,0.3) with a pruning rate of 0.3\n",
      "has more computational costs than (3,0.2,0.2) with a pruning rate of\n",
      "0.2. In Fig. 1(a), we can observe from the partial experimental results\n",
      "that at the accuracy requirement of 98.1%, the computation of the\n",
      "optimized models using three stages is less than that of the model using______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "has more computational costs than (3,0.2,0.2) with a pruning rate of\n",
      "0.2. In Fig. 1(a), we can observe from the partial experimental results\n",
      "that at the accuracy requirement of 98.1%, the computation of the\n",
      "optimized models using three stages is less than that of the model using\n",
      "two stages. But this law does not apply to the optimization effect of\n",
      "other accuracy requirements such as 98.7% and 98.8%. It is observed\n",
      "that the optimization effects of different configuration parameters are\n",
      "distinct and irregular under the specified accuracy requirement, and\n",
      "thus it is difficult to find an optimal model. This example shows that\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029783\f\n",
      "G. Li et al.\n",
      "\n",
      "Fig. 2. The optimization effect of staging-based strategy, pruning-based strategy, and\n",
      "CoAxNN for ResNet-56 on the CIFAR-10.\n",
      "\n",
      "it is challenging to combine different approximate strategies to achieve\n",
      "efficient optimization for neural network models.\n",
      "\n",
      "In this paper, for a specified accuracy requirement, we focus on______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "CoAxNN for ResNet-56 on the CIFAR-10.\n",
      "\n",
      "it is challenging to combine different approximate strategies to achieve\n",
      "efficient optimization for neural network models.\n",
      "\n",
      "In this paper, for a specified accuracy requirement, we focus on\n",
      "combining the principles of different approximate strategies to con-\n",
      "struct a design space and automatically search for reasonable con-\n",
      "figuration parameters, giving full play to the advantages of different\n",
      "approximate strategies to achieve efficient optimization for neural net-\n",
      "work models. As shown in Fig. 2, at the accuracy requirement of\n",
      "99.6%, for the staging-based optimization strategy, the two stages are\n",
      "used and the threshold is set to 0.07 for each stage, the normalized\n",
      "computational cost is 0.89. For the pruning-based optimization, the\n",
      "pruning rate is set to 0.1, and the normalized computational cost is\n",
      "0.89. CoAxNN effectively combines pruning-based and staging-based\n",
      "strategies, whose computational cost is 0.64, greatly improving the\n",
      "computational performance.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "computational cost is 0.89. For the pruning-based optimization, the\n",
      "pruning rate is set to 0.1, and the normalized computational cost is\n",
      "0.89. CoAxNN effectively combines pruning-based and staging-based\n",
      "strategies, whose computational cost is 0.64, greatly improving the\n",
      "computational performance.\n",
      "\n",
      "3. Methodology\n",
      "\n",
      "3.1. Overview\n",
      "\n",
      "In this paper, we propose an efficient optimization framework for\n",
      "neural network models, CoAxNN, which automatically searches for\n",
      "reasonable configuration parameters through a GA-based DSE. CoAxNN\n",
      "effectively combines staging-based with pruning-based approximate\n",
      "strategies to make full use of the superiority of both, thereby improving\n",
      "the actual performance while meeting the accuracy requirements for\n",
      "neural network models.\n",
      "\n",
      "The overview of the CoAxNN is shown in Fig. 3. First, for the\n",
      "original deep neural network model, CoAxNN performs staging-based\n",
      "and pruning-based approximate strategies according to the genes of\n",
      "the chromosome for each individual, which generates a compressed______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "neural network models.\n",
      "\n",
      "The overview of the CoAxNN is shown in Fig. 3. First, for the\n",
      "original deep neural network model, CoAxNN performs staging-based\n",
      "and pruning-based approximate strategies according to the genes of\n",
      "the chromosome for each individual, which generates a compressed\n",
      "multi-stage model. According to the availability of stages in the gene,\n",
      "CoAxNN attaches exit branches to the original model to build a multi-\n",
      "stage conditional activation model. According to the threshold of each\n",
      "stage, CoAxNN predicts input samples, having distinct difficulties, by\n",
      "multiple stages with different computational complexities, with the\n",
      "entropy-aware activation manner. The obtained multi-stage model is\n",
      "compressed by removing unimportant filters, thereby further reducing\n",
      "computational costs. Next, CoAxNN evaluates the fitness of the cor-\n",
      "responding individual according to the accuracy and latency of the\n",
      "compressed multi-stage model and sorts the individuals according to______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "compressed by removing unimportant filters, thereby further reducing\n",
      "computational costs. Next, CoAxNN evaluates the fitness of the cor-\n",
      "responding individual according to the accuracy and latency of the\n",
      "compressed multi-stage model and sorts the individuals according to\n",
      "their fitness. Then, the chromosome pool is updated, generating the\n",
      "next generation of individuals. After the evolution of multiple gener-\n",
      "ations, which repeat the above steps, we can obtain several individuals\n",
      "that have optimal performance.\n",
      "\n",
      "3.2. Staging-based approximate optimization\n",
      "\n",
      "In general, executing a neural network model is a one-staged ap-\n",
      "proach, which processes all the inputs in the same manner, i.e., starting\n",
      "from the input operator and performing it operator by operator until\n",
      "the final exit operator. Prior studies [19] found that classification\n",
      "difficulty varies widely across inputs in real-world scenarios. Different\n",
      "computational complexities need to be considered when predicting in-______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "from the input operator and performing it operator by operator until\n",
      "the final exit operator. Prior studies [19] found that classification\n",
      "difficulty varies widely across inputs in real-world scenarios. Different\n",
      "computational complexities need to be considered when predicting in-\n",
      "puts. Most of the input samples can be correctly classified by employing\n",
      "\n",
      "a part of a neural network, without the computation effort of the\n",
      "entire neural network. Early exiting strategy often comes into play,\n",
      "which allows simple inputs to exit early with a good prediction by the\n",
      "addition of multiple exit points. By leveraging the early exiting strategy,\n",
      "CoAxNN achieves a staging-based approximation to give an early exit-\n",
      "ing opportunity for simple inputs. We denote a neural network model\n",
      "as  = {𝑓1, 𝑓2, … , 𝑓𝑚} which consists of 𝑚 operators. In CoAxNN, a\n",
      "multi-stage model,  ∗, can be formalized as follows:\n",
      "\n",
      " ∗ =\n",
      "\n",
      "𝜏\n",
      "⋃\n",
      "\n",
      "𝑖=0\n",
      "\n",
      "\n",
      "𝑖\n",
      "\n",
      "(1)\n",
      "\n",
      "where 𝜏 is the number of stages.\n",
      "\n",
      "The ______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "ing opportunity for simple inputs. We denote a neural network model\n",
      "as  = {𝑓1, 𝑓2, … , 𝑓𝑚} which consists of 𝑚 operators. In CoAxNN, a\n",
      "multi-stage model,  ∗, can be formalized as follows:\n",
      "\n",
      " ∗ =\n",
      "\n",
      "𝜏\n",
      "⋃\n",
      "\n",
      "𝑖=0\n",
      "\n",
      "\n",
      "𝑖\n",
      "\n",
      "(1)\n",
      "\n",
      "where 𝜏 is the number of stages.\n",
      "\n",
      "The \n",
      "\n",
      "𝑖 is an approximate model with the staging-based strategy,\n",
      "\n",
      "which can be formalized as:\n",
      "\n",
      "\n",
      "\n",
      "𝑖 =\n",
      "\n",
      "{\n",
      "\n",
      "𝑖 + \n",
      "\n",
      "𝑖 + \n",
      " , 𝑖 = 𝜏\n",
      "\n",
      "𝑖, 1 ⩽ 𝑖 < 𝜏\n",
      "\n",
      "(2)\n",
      "\n",
      "𝑖 = {𝑓1, 𝑓2, … , 𝑓𝑝𝑖\n",
      "\n",
      "where \n",
      "} represents a part of the original neural\n",
      "network with 𝑝𝑖 operators, \n",
      ", … , 𝑓 ∗\n",
      ", 𝑓 ∗\n",
      "} represents an addi-\n",
      "𝑏𝑖\n",
      "2\n",
      "tional exit branch with 𝑏𝑖 operators, and \n",
      "𝑖 = {𝑐𝑖, 𝜀𝑖} represents an exit\n",
      "checker, containing a threshold 𝜀𝑖 and a conditional activation operator\n",
      "𝜏 =  denotes the original (main)\n",
      "𝑐𝑖 using threshold 𝜀𝑖. Especially, \n",
      "neural network model.\n",
      "\n",
      "𝑖 = {𝑓 ∗\n",
      "1\n",
      "\n",
      "It is non-trivial to design a staging-based approximate strategy\n",
      "for adaptive conditional inference of a multi-stage model, and the\n",
      "following factors need to be considered:\n",
      "\n",
      "• Number of ______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "𝜏 =  denotes the original (main)\n",
      "𝑐𝑖 using threshold 𝜀𝑖. Especially, \n",
      "neural network model.\n",
      "\n",
      "𝑖 = {𝑓 ∗\n",
      "1\n",
      "\n",
      "It is non-trivial to design a staging-based approximate strategy\n",
      "for adaptive conditional inference of a multi-stage model, and the\n",
      "following factors need to be considered:\n",
      "\n",
      "• Number of \n",
      "\n",
      "𝒊. A multi-stage model with arbitrary exits can be built\n",
      "by stage availability. However, fewer exits cannot cover the diverse\n",
      "difficulty of classification of input samples, whereas too many exits\n",
      "increase the latency of hard samples that do not exit early.\n",
      "\n",
      "• Selection of Attached Position (𝒑𝒊) for \n",
      "\n",
      "𝒊. The exits at a more for-\n",
      "mer position cannot provide satisfactory accuracy, while redundant\n",
      "computation may be involved at a more latter exit. Besides, attached\n",
      "exit branches may also interfere with a variety of computational\n",
      "graph optimization methods, such as operator fusion and mem-\n",
      "ory reuse, provided by the deep learning frameworks, increasing\n",
      "operation counts, data movement, and other system overheads.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "exit branches may also interfere with a variety of computational\n",
      "graph optimization methods, such as operator fusion and mem-\n",
      "ory reuse, provided by the deep learning frameworks, increasing\n",
      "operation counts, data movement, and other system overheads.\n",
      "\n",
      "• Confidence Threshold (𝜺𝒊) of \n",
      "\n",
      "𝒊. The confidence threshold is used\n",
      "to determine whether the prediction result of stage \n",
      "𝑖 has sufficient\n",
      "confidence. With a higher threshold, complex samples may finish\n",
      "predictions from the previous exits with lower accuracy, and using\n",
      "a lower threshold, simple samples may use more complex compu-\n",
      "tations to complete inference, due to cannot end from the previous\n",
      "classifiers, incurring additional computational overheads.\n",
      "\n",
      "• Structure Design for \n",
      "𝒊. The structure of each exit branch (\n",
      "𝑖)\n",
      "is not identical. Each \n",
      ", 𝑓 ∗\n",
      "𝑖 consists of several operators ({𝑓 ∗\n",
      ", … ,\n",
      "2\n",
      "1\n",
      "𝑓 ∗\n",
      "𝑏𝑖−1}) used for feature extraction and a linear classifier 𝑓 ∗\n",
      ". Feature\n",
      "𝑏𝑖\n",
      "extraction operators receive the intermediate feature map from 𝑓𝑝𝑖______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "• Structure Design for \n",
      "𝒊. The structure of each exit branch (\n",
      "𝑖)\n",
      "is not identical. Each \n",
      ", 𝑓 ∗\n",
      "𝑖 consists of several operators ({𝑓 ∗\n",
      ", … ,\n",
      "2\n",
      "1\n",
      "𝑓 ∗\n",
      "𝑏𝑖−1}) used for feature extraction and a linear classifier 𝑓 ∗\n",
      ". Feature\n",
      "𝑏𝑖\n",
      "extraction operators receive the intermediate feature map from 𝑓𝑝𝑖\n",
      "and extract more high-level features in the form required by a\n",
      "subsequent linear classifier. The configuration and complexity of the\n",
      "intermediate feature maps for different depths of the main neural\n",
      "networks are varying, making the design of \n",
      "𝑖 arduous. The 𝑓 ∗\n",
      "𝑏𝑖\n",
      "operator is used to produce classification results based on the output\n",
      "of 𝑓 ∗\n",
      "is different at\n",
      "each \n",
      "𝑖.\n",
      "\n",
      "𝑏𝑖−1, and the number of input feature maps for 𝑓 ∗\n",
      "𝑏𝑖\n",
      "\n",
      "To effectively utilize the early-exiting method to build an approxi-\n",
      "mate multi-stage model, our approach carefully designs principles for\n",
      "each module.\n",
      "\n",
      "• Setting of Number (𝜏) and Attached Position (𝒑𝒊) of \n",
      "𝒊. The\n",
      "number (𝜏) and the position (𝒑𝒊) of the exit branches (\n",
      "𝒊) are two______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "𝑏𝑖\n",
      "\n",
      "To effectively utilize the early-exiting method to build an approxi-\n",
      "mate multi-stage model, our approach carefully designs principles for\n",
      "each module.\n",
      "\n",
      "• Setting of Number (𝜏) and Attached Position (𝒑𝒊) of \n",
      "𝒊. The\n",
      "number (𝜏) and the position (𝒑𝒊) of the exit branches (\n",
      "𝒊) are two\n",
      "factors that will affect each other. Some unnecessary exits may\n",
      "be inserted, having little improvement in accuracy but leading to\n",
      "non-negligible computational overheads, when the number of exit\n",
      "branches is large. When the position of the exit branch is not\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029784\f\n",
      "G. Li et al.\n",
      "\n",
      "Fig. 3. Overview of CoAxNN.\n",
      "\n",
      "• Structure Design for \n",
      "\n",
      "reasonable, and cannot distinguish the difficulty of the sample, it\n",
      "is difficult to increase the number of exit branches to reduce the\n",
      "computational cost while meeting the model accuracy requirement.\n",
      "To address this problem, CoAxNN puts the availability of each stage\n",
      "into the design space of the GA, and each available stage corresponds______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "is difficult to increase the number of exit branches to reduce the\n",
      "computational cost while meeting the model accuracy requirement.\n",
      "To address this problem, CoAxNN puts the availability of each stage\n",
      "into the design space of the GA, and each available stage corresponds\n",
      "to a new exit branch. The availability of the stage can control the\n",
      "number and position of exit branches at the same time. Besides,\n",
      "to introduce fewer new model structures and preserve the existing\n",
      "graph optimizations, CoAxNN chooses to attach exit branches \n",
      "𝑖 at\n",
      "the end of the group of building blocks. It is noted that CoAxNN does\n",
      "not attach the exit branch after the last group of building blocks, as\n",
      "there is already an existing original exit for the original backbone.\n",
      "𝒊. We introduce a feature extractor and\n",
      "a linear classifier for each exit branch \n",
      "𝑖. The structure of the\n",
      "feature extractor is designed with the building block as granularity.\n",
      "This design not only retains the original neural network structure______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "𝒊. We introduce a feature extractor and\n",
      "a linear classifier for each exit branch \n",
      "𝑖. The structure of the\n",
      "feature extractor is designed with the building block as granularity.\n",
      "This design not only retains the original neural network structure\n",
      "but also provides more opportunities for system-level optimizations.\n",
      "Generally, operators for feature extraction also contain non-linear\n",
      "activation operators such as rectified linear units, and normalization\n",
      "operators such as batch normalization. Besides, prior studies [24]\n",
      "revealed that the output feature maps of operators at shallow depths\n",
      "of a neural network have a relatively large height and width, which\n",
      "results in a large number of input feature maps being passed to the\n",
      "linear classifier of former exits, thus leading to a long latency for\n",
      "easy samples that exit early. As such, in CoAxNN, we add an extra\n",
      "pooling operator after the last feature extraction operator of shallow\n",
      "\n",
      "𝑖.\n",
      "\n",
      "• Confidence Measure in \n",
      "\n",
      "𝒊. The \n",
      "\n",
      "𝑖. A reliable ______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "linear classifier of former exits, thus leading to a long latency for\n",
      "easy samples that exit early. As such, in CoAxNN, we add an extra\n",
      "pooling operator after the last feature extraction operator of shallow\n",
      "\n",
      "𝑖.\n",
      "\n",
      "• Confidence Measure in \n",
      "\n",
      "𝒊. The \n",
      "\n",
      "𝑖. A reliable \n",
      "\n",
      "𝑖 takes a threshold checking step,\n",
      "which determines whether an input returns from the current exit\n",
      "or continues to the next exit according to the prediction result\n",
      "of \n",
      "𝑖 should have the ability to identify whether\n",
      "the classification results are sufficiently confident. There are var-\n",
      "ious methods [31], including maximum probability, entropy, and\n",
      "margin, for the design of \n",
      "𝑖. Prior work [24] has demonstrated\n",
      "the performance of the aforementioned three confidence types is\n",
      "almost identical. CoAxNN chooses to use the entropy of predicted\n",
      "probability as the entropy-aware activation operator (𝑐𝑖) to evaluate\n",
      "the confidence of the prediction result for the input sample (𝑥) of\n",
      "the 𝑖th stage classifier, as follows:\n",
      "\n",
      "entropy( ̂𝑦𝑖) =\n",
      "\n",
      "𝐶\n",
      "∑\n",
      "\n",
      "𝑐=1______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "almost identical. CoAxNN chooses to use the entropy of predicted\n",
      "probability as the entropy-aware activation operator (𝑐𝑖) to evaluate\n",
      "the confidence of the prediction result for the input sample (𝑥) of\n",
      "the 𝑖th stage classifier, as follows:\n",
      "\n",
      "entropy( ̂𝑦𝑖) =\n",
      "\n",
      "𝐶\n",
      "∑\n",
      "\n",
      "𝑐=1\n",
      "\n",
      "̂𝑦𝑖(𝑐) log ̂𝑦𝑖(𝑐)\n",
      "\n",
      "(3)\n",
      "\n",
      "where ̂𝑦𝑖 is the probability distribution of the output of the linear\n",
      "classifier 𝑓 ∗\n",
      "on different classification labels, calculated by the soft-\n",
      "𝑏𝑖\n",
      "max operator, and 𝐶 is the number of classes. An entropy threshold\n",
      "𝜀𝑖 is used to decide whether an input returns the prediction of the\n",
      "current exit or activates the latter operators. A higher confidence\n",
      "value implies that the input sample that arrived at the current exit is\n",
      "hard and needs to be processed by a more complex stage to complete\n",
      "accurate classification.\n",
      "\n",
      "3.3. Pruning-based approximate optimization\n",
      "\n",
      "In addition to the staging-based approximate strategy that pro-\n",
      "vides adaptive computing based on conditional activation at runtime,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "hard and needs to be processed by a more complex stage to complete\n",
      "accurate classification.\n",
      "\n",
      "3.3. Pruning-based approximate optimization\n",
      "\n",
      "In addition to the staging-based approximate strategy that pro-\n",
      "vides adaptive computing based on conditional activation at runtime,\n",
      "CoAxNN also integrates a pruning-based approximate strategy to com-\n",
      "press model size. The neural network pruning technique has been\n",
      "widely studied by researchers, which can be broadly categorized as\n",
      "structured and unstructured pruning. Structured pruning such as filter\n",
      "pruning has higher computational efficiency than unstructured prun-\n",
      "ing [32]. Especially, filter pruning is employed, which not only deletes\n",
      "redundant computations of unimportant filters but also leads to the\n",
      "removal of corresponding feature maps, providing realistic performance\n",
      "improvements. In CoAxNN, we utilize the filter pruning method to\n",
      "compress the multi-stage model and quantify the importance of each\n",
      "filter in a convolutional operator based on the 𝓁2-norm:\n",
      "\n",
      "\n",
      "\n",
      "‖\n",
      "‖\n",
      "\n",
      "‖2 =______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "removal of corresponding feature maps, providing realistic performance\n",
      "improvements. In CoAxNN, we utilize the filter pruning method to\n",
      "compress the multi-stage model and quantify the importance of each\n",
      "filter in a convolutional operator based on the 𝓁2-norm:\n",
      "\n",
      "\n",
      "\n",
      "‖\n",
      "‖\n",
      "\n",
      "‖2 =\n",
      "𝑟‖\n",
      "\n",
      "√\n",
      "√\n",
      "√\n",
      "√\n",
      "√\n",
      "\n",
      "𝑘\n",
      "∑\n",
      "\n",
      "𝑚\n",
      "∑\n",
      "\n",
      "𝑛\n",
      "∑\n",
      "\n",
      "𝑡=1\n",
      "\n",
      "𝑖=1\n",
      "\n",
      "𝑗=1\n",
      "\n",
      "𝑤2\n",
      "\n",
      "𝑡,𝑖,𝑗\n",
      "\n",
      "(4)\n",
      "\n",
      "where \n",
      "𝑟 indicates the 𝑟th filter in a convolutional operator, 𝑤𝑡,𝑖,𝑗\n",
      "denotes an element of \n",
      "𝑟 that resides in the 𝑖th row and 𝑗th column\n",
      "in the 𝑡th channel, 𝑘 denotes the input channels, 𝑚 denotes the height\n",
      "of filters, and 𝑛 denotes the width of filters. The filters with smaller 𝓁2-\n",
      "norm will be given higher priority to be pruned than those of higher\n",
      "𝓁2-norm. To keep the model capacity and minimize the loss of accuracy\n",
      "as much as possible, we utilize a dynamic pruning scheme [2] for\n",
      "staging-based approximate CNNs, which zeroes the pruned filters and\n",
      "keeps updating them in the re-training process.\n",
      "\n",
      "3.4. Training of CoAxNN______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "𝓁2-norm. To keep the model capacity and minimize the loss of accuracy\n",
      "as much as possible, we utilize a dynamic pruning scheme [2] for\n",
      "staging-based approximate CNNs, which zeroes the pruned filters and\n",
      "keeps updating them in the re-training process.\n",
      "\n",
      "3.4. Training of CoAxNN\n",
      "\n",
      "Joint training trains all classifiers in a neural network model at\n",
      "the same time, which is widely used in the training process of neural\n",
      "network models with exit branches [18,27]. It defines a loss function\n",
      "for each classifier and minimizes the weighted sum of loss functions\n",
      "for all classifiers during training. Therefore, each classifier provides\n",
      "regularization for others to alleviate the overfitting of the model.\n",
      "CoAxNN utilizes joint training optimization to train the backbone\n",
      "neural network and exit branches at the same time and minimize the\n",
      "weighted sum of the cross-entropy loss functions of all stages, denoted\n",
      "as follows:\n",
      "\n",
      "\n",
      "\n",
      "joint =\n",
      "\n",
      "𝜏\n",
      "∑\n",
      "\n",
      "𝑖=1\n",
      "\n",
      "𝜆𝑖\n",
      "\n",
      "CE(𝑦, ̄𝑦𝑖)\n",
      "\n",
      "\n",
      "(5)______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "CoAxNN utilizes joint training optimization to train the backbone\n",
      "neural network and exit branches at the same time and minimize the\n",
      "weighted sum of the cross-entropy loss functions of all stages, denoted\n",
      "as follows:\n",
      "\n",
      "\n",
      "\n",
      "joint =\n",
      "\n",
      "𝜏\n",
      "∑\n",
      "\n",
      "𝑖=1\n",
      "\n",
      "𝜆𝑖\n",
      "\n",
      "CE(𝑦, ̄𝑦𝑖)\n",
      "\n",
      "\n",
      "(5)\n",
      "\n",
      "where 𝜆𝑖 represents the weight of the loss function of the 𝑖th stage,\n",
      "𝑦 is the real classification of 𝑥 which is shared by all stages, ̄𝑦𝑖 is the\n",
      "output of linear classifier 𝑓 ∗\n",
      "of the 𝑖th stage, and the cross-entropy loss\n",
      "𝑏𝑖\n",
      "function \n",
      "\n",
      "CE is calculated as follows:\n",
      "\n",
      "CE(𝑦, ̄𝑦𝑖) = −\n",
      "\n",
      "\n",
      "𝐶\n",
      "∑\n",
      "\n",
      "𝑐=1\n",
      "\n",
      "𝑦(𝑐) log\n",
      "\n",
      "e ̄𝑦𝑖(𝑐)\n",
      "𝑗=1 e ̄𝑦𝑖(𝑗)\n",
      "\n",
      "∑𝐶\n",
      "\n",
      "(6)\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029785\f\n",
      "G. Li et al.\n",
      "\n",
      "The training process of CoAxNN is summarized in Algorithm 1.\n",
      "It is given training dataset , training epochs 𝑒𝑝𝑜𝑐ℎ𝑚𝑎𝑥, batch size\n",
      "𝜌, original deep neural network model  , number of stages 𝜏, the\n",
      "weights for loss functions of all stages 𝜆, and the chromosome pool\n",
      "𝑃 . First, based on the genes on the chromosome, CoAxNN performs a______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "It is given training dataset , training epochs 𝑒𝑝𝑜𝑐ℎ𝑚𝑎𝑥, batch size\n",
      "𝜌, original deep neural network model  , number of stages 𝜏, the\n",
      "weights for loss functions of all stages 𝜆, and the chromosome pool\n",
      "𝑃 . First, based on the genes on the chromosome, CoAxNN performs a\n",
      "staging-based optimization strategy, which approximates the original\n",
      "neural network model as a multi-stage conditional activation model\n",
      "by attaching exit branches (Lines 1–11). Then, the generated multi-\n",
      "stage model is initialized randomly (Lines 12–13). Next, the model\n",
      "is compressed and tuned according to the training data  and the\n",
      "gene of the pruning rate (𝑃 [𝑝].𝑝𝑟𝑢𝑛𝑖𝑛𝑔_𝑟𝑎𝑡𝑒) on the chromosome in\n",
      "𝑒𝑝𝑜𝑐ℎ𝑚𝑎𝑥 epochs (Lines 14–34). In each epoch, CoAxNN calculates the\n",
      "loss function according to Eq. (5) and updates the weights by the\n",
      "traditional backpropagation algorithm (Lines 15–26). Besides, for each\n",
      "convolutional operator in the approximate multi-stage model, CoAxNN\n",
      "obtains the number of filters (𝑡) and calculates the 𝓁2-norm of each______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "loss function according to Eq. (5) and updates the weights by the\n",
      "traditional backpropagation algorithm (Lines 15–26). Besides, for each\n",
      "convolutional operator in the approximate multi-stage model, CoAxNN\n",
      "obtains the number of filters (𝑡) and calculates the 𝓁2-norm of each\n",
      "filter according to Eq. (4), then the dynamic pruning scheme is used\n",
      "to prune ⌊𝑡 × 𝑃 [𝑝].𝑝𝑟𝑢𝑛𝑖𝑛𝑔_𝑟𝑎𝑡𝑒⌋ filters with low 𝓁2-norm (Lines 27–33).\n",
      "The pruned filters can be updated once it is found to be important at\n",
      "any time, thus maintaining the learning ability of the model. In the\n",
      "pruning process of each epoch, CoAxNN will reorder the importance\n",
      "of filters for each convolutional operator, and select the filters to be\n",
      "pruned. Finally, the trained model  ′ is obtained (Line 36).\n",
      "\n",
      "Algorithm 1: CoAxNN training\n",
      "\n",
      "Input: training data: , training epoch: 𝑒𝑝𝑜𝑐ℎ𝑚𝑎𝑥, batch size: 𝜌,\n",
      "\n",
      "original model backbone:  , the number of stages: 𝜏, the\n",
      "weights for loss functions: 𝜆, chromosomes: 𝑃\n",
      "\n",
      "Output: trained models:  ′\n",
      "\n",
      "1 for 𝑝 = 1 → 𝑃 .𝑠𝑖𝑧𝑒() do______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Algorithm 1: CoAxNN training\n",
      "\n",
      "Input: training data: , training epoch: 𝑒𝑝𝑜𝑐ℎ𝑚𝑎𝑥, batch size: 𝜌,\n",
      "\n",
      "original model backbone:  , the number of stages: 𝜏, the\n",
      "weights for loss functions: 𝜆, chromosomes: 𝑃\n",
      "\n",
      "Output: trained models:  ′\n",
      "\n",
      "1 for 𝑝 = 1 → 𝑃 .𝑠𝑖𝑧𝑒() do\n",
      "\n",
      "// Generate model structure\n",
      " ′[𝑝] =  ;\n",
      "for 𝑖 = 1 → 𝜏 − 1 do\n",
      "\n",
      "if P[p][i] is available then\n",
      "𝑖 from  ;\n",
      "Construct \n",
      "𝑖 according to \n",
      "Construct \n",
      "Construct \n",
      "𝑖 according to 𝑃 [𝑝][𝑖].𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑;\n",
      "\n",
      "𝑖 + \n",
      "𝑖 + \n",
      "𝑖 = \n",
      "𝑖;\n",
      " ′[𝑝] =  ′[𝑝] ∪ \n",
      "\n",
      "𝑖;\n",
      "\n",
      "𝑖;\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "// Tune and prune model parameters\n",
      " ′[𝑝] = LoadModel( ′[𝑝], 𝑖𝑛𝑖𝑡𝑎𝑙_𝑤𝑒𝑖𝑔ℎ𝑡𝑠);\n",
      "𝑡𝑟𝑎𝑖𝑛_𝑏𝑎𝑡𝑐ℎ𝑒𝑠 = make_batch(, 𝜌);\n",
      "for 𝑒𝑝𝑜𝑐ℎ = 1 → 𝑒𝑝𝑜𝑐ℎ𝑚𝑎𝑥 do\n",
      "\n",
      "foreach (𝑖𝑛𝑝𝑢𝑡, 𝑡𝑎𝑟𝑔𝑒𝑡) ∈ 𝑡𝑟𝑎𝑖𝑛_𝑏𝑎𝑡𝑐ℎ𝑒𝑠 do\n",
      "𝑜𝑢𝑡𝑝𝑢𝑡 =  ′[𝑝].forward(𝑖𝑛𝑝𝑢𝑡);\n",
      "𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠 ← 0;\n",
      "for 𝑖 = 1 → 𝜏 do\n",
      "\n",
      "if P[p][i] is available then\n",
      "\n",
      "𝑙𝑜𝑠𝑠 = CrossEntropy(𝑜𝑢𝑡𝑝𝑢𝑡[𝑖], 𝑡𝑎𝑟𝑔𝑒𝑡);\n",
      "𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠 += 𝜆[𝑖] × 𝑙𝑜𝑠𝑠;\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠 = 𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠∕𝑠𝑢𝑚(𝜆);\n",
      " ′[𝑝].backward(𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠);\n",
      "\n",
      "end\n",
      "foreach 𝑓 ∈  ′[𝑝] do\n",
      "\n",
      "if 𝑓 .𝑡𝑦𝑝𝑒 == 𝐶𝑂𝑁𝑉 then______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠 ← 0;\n",
      "for 𝑖 = 1 → 𝜏 do\n",
      "\n",
      "if P[p][i] is available then\n",
      "\n",
      "𝑙𝑜𝑠𝑠 = CrossEntropy(𝑜𝑢𝑡𝑝𝑢𝑡[𝑖], 𝑡𝑎𝑟𝑔𝑒𝑡);\n",
      "𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠 += 𝜆[𝑖] × 𝑙𝑜𝑠𝑠;\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠 = 𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠∕𝑠𝑢𝑚(𝜆);\n",
      " ′[𝑝].backward(𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑_𝑙𝑜𝑠𝑠);\n",
      "\n",
      "end\n",
      "foreach 𝑓 ∈  ′[𝑝] do\n",
      "\n",
      "if 𝑓 .𝑡𝑦𝑝𝑒 == 𝐶𝑂𝑁𝑉 then\n",
      "\n",
      "𝑡 ← the filters number of 𝑓 ;\n",
      "Calculate the 𝓁2-norm for the filters;\n",
      "Zeroize the lowest filters ⌊𝑡 × 𝑃 [𝑝].𝑝𝑟𝑢𝑛𝑖𝑛𝑔_𝑟𝑎𝑡𝑒⌋ filters;\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "\n",
      "11\n",
      "\n",
      "12\n",
      "\n",
      "13\n",
      "\n",
      "14\n",
      "\n",
      "15\n",
      "\n",
      "16\n",
      "\n",
      "17\n",
      "\n",
      "18\n",
      "\n",
      "19\n",
      "\n",
      "20\n",
      "\n",
      "21\n",
      "\n",
      "22\n",
      "\n",
      "23\n",
      "\n",
      "24\n",
      "\n",
      "25\n",
      "\n",
      "26\n",
      "\n",
      "27\n",
      "\n",
      "28\n",
      "\n",
      "29\n",
      "\n",
      "30\n",
      "\n",
      "31\n",
      "\n",
      "32\n",
      "\n",
      "33\n",
      "\n",
      "34\n",
      "\n",
      "3.5. GA-based design space exploration\n",
      "\n",
      "To effectively combine the staging-based with the pruning-based ap-\n",
      "proximate strategies, the design space of CoAxNN includes the number\n",
      "of stages, the position of the stage, the threshold of the stage, and the\n",
      "pruning rate, which is a very large search space. When the number of\n",
      "stages is 𝜏, the search space for determining which stage is available\n",
      "is 2𝜏 , the search space for thresholds is 𝑄𝜏 where 𝑄 is the number______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "of stages, the position of the stage, the threshold of the stage, and the\n",
      "pruning rate, which is a very large search space. When the number of\n",
      "stages is 𝜏, the search space for determining which stage is available\n",
      "is 2𝜏 , the search space for thresholds is 𝑄𝜏 where 𝑄 is the number\n",
      "of candidate thresholds, and the search space for pruning rate is 𝑅,\n",
      "which indicates the number of candidate pruning rates. The parameter\n",
      "configurations are searched independently, making the search space as\n",
      "large as 2𝜏 × 𝑄𝜏 × 𝑅. It is laborious to explore the large parameter\n",
      "space by brute force search. CoAxNN adopts the genetic algorithm\n",
      "for the design space exploration. Genetic algorithm [33] is inspired by\n",
      "biological evolution based on Charles Darwin’s theory of natural selec-\n",
      "tion, which is often used to find the (near-)optimal solution in a large\n",
      "search space. In CoAxNN, the number of genes on each chromosome is\n",
      "2 × (𝜏 − 1) + 1. For the first 𝜏 − 1 stages, CoAxNN uses two genes, one for______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "biological evolution based on Charles Darwin’s theory of natural selec-\n",
      "tion, which is often used to find the (near-)optimal solution in a large\n",
      "search space. In CoAxNN, the number of genes on each chromosome is\n",
      "2 × (𝜏 − 1) + 1. For the first 𝜏 − 1 stages, CoAxNN uses two genes, one for\n",
      "whether the stage is available, and the other for the threshold of the\n",
      "stage. In addition, CoAxNN also uses a gene to represent the pruning\n",
      "ratio. The fitness of the single individual is represented by a 2-tuple\n",
      "(𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦, 𝑙𝑎𝑡𝑒𝑛𝑐𝑦). GA-based DSE aims to increase accuracy and reduce\n",
      "latency, finding the (near-)optimal solutions for model performance.\n",
      "\n",
      "Algorithm 2 shows that how accuracy and latency are evaluated\n",
      "for individuals. It is given the test dataset , the number of stages 𝜏,\n",
      "and the chromosome set 𝑃 . For each individual, CoAxNN obtains the\n",
      "model 𝑛𝑒𝑡 configured with the corresponding gene (Line 4). Then, the\n",
      "test dataset  is predicted by the model, and the result of prediction______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "for individuals. It is given the test dataset , the number of stages 𝜏,\n",
      "and the chromosome set 𝑃 . For each individual, CoAxNN obtains the\n",
      "model 𝑛𝑒𝑡 configured with the corresponding gene (Line 4). Then, the\n",
      "test dataset  is predicted by the model, and the result of prediction\n",
      "𝑜𝑢𝑡𝑝𝑢𝑡 is got (Line 6). For each input sample, CoAxNN traverses all\n",
      "available stages and calculates the confidence 𝑒 of corresponding output\n",
      "at this stage according to Eq. (3) (Lines 7–12). If the confidence (𝑒)\n",
      "is less than the confidence threshold (𝜀𝑖) of this stage, the prediction\n",
      "is ended, and the accuracy of the sample at this stage is added to\n",
      "the accuracy score (𝛿[𝑝]) of the current individual (𝑝) (Lines 13–16).\n",
      "The accuracy function returns 1 if the prediction is correct, and 0\n",
      "otherwise. When the sample does not exit from the first 𝜏 − 1 stages,\n",
      "it must be exited from the 𝜏th stage. Therefore, in the 𝜏th stage, the\n",
      "accuracy is directly added to the accuracy score (𝛿[𝑝]) (Lines 17–19).______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "The accuracy function returns 1 if the prediction is correct, and 0\n",
      "otherwise. When the sample does not exit from the first 𝜏 − 1 stages,\n",
      "it must be exited from the 𝜏th stage. Therefore, in the 𝜏th stage, the\n",
      "accuracy is directly added to the accuracy score (𝛿[𝑝]) (Lines 17–19).\n",
      "The evaluation of latency is similar to accuracy. CoAxNN evaluates the\n",
      "latency score (𝜇[𝑝]) using a similar manner as the accuracy score (𝛿[𝑝]),\n",
      "which accumulates the latency of the backbone neural network and exit\n",
      "branches until the end of the prediction (Line 8–10). For the latency,\n",
      "we test the original network with all possible exit branches attached on\n",
      "the target edge devices. The execution time of all operators is recorded.\n",
      "Finally, the average accuracy score (𝛿) and average latency score (𝜇) for\n",
      "all individuals are obtained (Lines 23–26).\n",
      "\n",
      "GA-based DSE gets the (near-)optimal solutions about the goal of\n",
      "accuracy and latency. Users choose the (near-)optimal solution among______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Finally, the average accuracy score (𝛿) and average latency score (𝜇) for\n",
      "all individuals are obtained (Lines 23–26).\n",
      "\n",
      "GA-based DSE gets the (near-)optimal solutions about the goal of\n",
      "accuracy and latency. Users choose the (near-)optimal solution among\n",
      "them according to their requirements. If the accuracy requirement is\n",
      "high, the model with the least computation cost is selected under a triv-\n",
      "ial accuracy loss. If a certain accuracy loss can be tolerated, the model\n",
      "with greatly less computation cost is selected. Finally, unavailable\n",
      "branches and unimportant filters are removed to obtain an optimized\n",
      "neural network model.\n",
      "\n",
      "4. Evaluation\n",
      "\n",
      "4.1. Experimental setting\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "Evaluation Platforms. We conduct optimization with PaddlePaddle,2\n",
      "an open-sourced deep learning framework, for neural network models\n",
      "on a server with Intel Xeon CPUs and an Nvidia A100 GPU. We evaluate\n",
      "\n",
      "35 end\n",
      "36 return  ′;\n",
      "\n",
      "2 https://www.paddlepaddle.org.cn/en.\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029786\f\n",
      "G. Li et al.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "an open-sourced deep learning framework, for neural network models\n",
      "on a server with Intel Xeon CPUs and an Nvidia A100 GPU. We evaluate\n",
      "\n",
      "35 end\n",
      "36 return  ′;\n",
      "\n",
      "2 https://www.paddlepaddle.org.cn/en.\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029786\f\n",
      "G. Li et al.\n",
      "\n",
      "Algorithm 2: Performance Collection\n",
      "\n",
      "Input: test data: , the number of stages: 𝜏, chromosomes: 𝑃\n",
      "Output: accuracy for each configuration of neural network\n",
      "models: 𝛿, latency for each configuration of neural\n",
      "network models: 𝜇\n",
      "\n",
      "1 for 𝑝 = 1 → 𝑃 .𝑠𝑖𝑧𝑒() do\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "\n",
      "11\n",
      "\n",
      "12\n",
      "\n",
      "13\n",
      "\n",
      "14\n",
      "\n",
      "15\n",
      "\n",
      "16\n",
      "\n",
      "17\n",
      "\n",
      "18\n",
      "\n",
      "19\n",
      "\n",
      "20\n",
      "\n",
      "21\n",
      "\n",
      "22\n",
      "\n",
      "23\n",
      "\n",
      "24\n",
      "\n",
      "𝛿[𝑝] ← 0;\n",
      "𝜇[𝑝] ← 0;\n",
      "𝑛𝑒𝑡 = getModel(𝑃 [𝑝]);\n",
      "foreach (𝑖𝑛𝑝𝑢𝑡, 𝑡𝑎𝑟𝑔𝑒𝑡) ∈  do\n",
      "𝑜𝑢𝑡𝑝𝑢𝑡 = 𝑛𝑒𝑡.forward(𝑖𝑛𝑝𝑢𝑡);\n",
      "for 𝑖 = 1 → 𝜏 do\n",
      "\n",
      "𝜇[𝑝] += computeLatency(\n",
      "if P[p][i] is available then\n",
      "\n",
      "𝑖);\n",
      "\n",
      "𝜇[𝑝] += computeLatency(⋃𝑖\n",
      "if 𝑖 ≠ 𝜏 then\n",
      "\n",
      "\n",
      "\n",
      "𝑗 );\n",
      "\n",
      "𝑗=1\n",
      "\n",
      "𝑒 ← Compute entropy of 𝑜𝑢𝑡𝑝𝑢𝑡[𝑖];\n",
      "if 𝑒 < 𝜀𝑖 then\n",
      "\n",
      "𝛿[𝑝] += accuracy(𝑜𝑢𝑡𝑝𝑢𝑡[𝑖], 𝑡𝑎𝑟𝑔𝑒𝑡);\n",
      "break;\n",
      "\n",
      "end\n",
      "\n",
      "else\n",
      "\n",
      "𝛿[𝑝] += accuracy(𝑜𝑢𝑡𝑝𝑢𝑡[𝑖], 𝑡𝑎𝑟𝑔𝑒𝑡);\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "𝛿[𝑝] = 𝛿[𝑝]∕.𝑠𝑖𝑧𝑒();______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "𝜇[𝑝] += computeLatency(\n",
      "if P[p][i] is available then\n",
      "\n",
      "𝑖);\n",
      "\n",
      "𝜇[𝑝] += computeLatency(⋃𝑖\n",
      "if 𝑖 ≠ 𝜏 then\n",
      "\n",
      "\n",
      "\n",
      "𝑗 );\n",
      "\n",
      "𝑗=1\n",
      "\n",
      "𝑒 ← Compute entropy of 𝑜𝑢𝑡𝑝𝑢𝑡[𝑖];\n",
      "if 𝑒 < 𝜀𝑖 then\n",
      "\n",
      "𝛿[𝑝] += accuracy(𝑜𝑢𝑡𝑝𝑢𝑡[𝑖], 𝑡𝑎𝑟𝑔𝑒𝑡);\n",
      "break;\n",
      "\n",
      "end\n",
      "\n",
      "else\n",
      "\n",
      "𝛿[𝑝] += accuracy(𝑜𝑢𝑡𝑝𝑢𝑡[𝑖], 𝑡𝑎𝑟𝑔𝑒𝑡);\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "𝛿[𝑝] = 𝛿[𝑝]∕.𝑠𝑖𝑧𝑒();\n",
      "𝜇[𝑝] = 𝜇[𝑝]∕.𝑠𝑖𝑧𝑒();\n",
      "\n",
      "25 end\n",
      "26 return (𝛿, 𝜇);\n",
      "\n",
      "the realistic speedup and energy consumption of optimized models on\n",
      "a representative intelligent edge platform, Jetson AGX Orin, integrated\n",
      "with Ampere GPUs and Arm Cortex CPUs. For the genetic algorithm,\n",
      "we adopted the OpenGA [34] and the NSGA-III [35].\n",
      "\n",
      "Benchmark Datasets and Models. We demonstrate the effectiveness\n",
      "of our proposed method on the CIFAR [36] dataset and the CINIC-\n",
      "10 [37] dataset. The CIFAR dataset, which consists of 50,000 images for\n",
      "training and 10,000 images for testing, contains two datasets: CIFAR-10\n",
      "and CIFAR-100. The CIFAR-10 and CIFAR-100 datasets are categorized\n",
      "into 10 and 100 classes, respectively. CINIC-10 consisting of 27 000______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "10 [37] dataset. The CIFAR dataset, which consists of 50,000 images for\n",
      "training and 10,000 images for testing, contains two datasets: CIFAR-10\n",
      "and CIFAR-100. The CIFAR-10 and CIFAR-100 datasets are categorized\n",
      "into 10 and 100 classes, respectively. CINIC-10 consisting of 27 000\n",
      "images is split into three equal-sized train, validation, and test subsets\n",
      "and is categorized into 10 classes. We adopt the state-of-the-art residual\n",
      "neural network (ResNet) [1], which has less redundancy and is more\n",
      "challenging to be compressed and accelerated than conventional model\n",
      "structures, as model architectures. ResNet-20/32/56/110 models are\n",
      "evaluated for the CIFAR-10 dataset, ResNet-56/110 models are evalu-\n",
      "ated for the CIFAR-100 dataset and ResNet-18/50 models are evaluated\n",
      "for the CINIC-10 dataset.\n",
      "\n",
      "Hyper-parameters Setting. For staging-based approximation, we at-\n",
      "tach exit branches after each residual block by default for building a\n",
      "multi-stage model, and the weight of the loss function of each stage is______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "for the CINIC-10 dataset.\n",
      "\n",
      "Hyper-parameters Setting. For staging-based approximation, we at-\n",
      "tach exit branches after each residual block by default for building a\n",
      "multi-stage model, and the weight of the loss function of each stage is\n",
      "set to 1.0 by default. For pruning-based approximation, we follow the\n",
      "same data argumentation strategies and scheduling settings as [1].\n",
      "\n",
      "4.2. GA-based design space exploration\n",
      "\n",
      "The GA-based DSE, taking increasing accuracy and reducing latency\n",
      "as the goal, evaluates and sorts the solutions in the design space, and\n",
      "obtains the (near-)optimal solutions about accuracy and latency after\n",
      "multiple generations of individuals. After the process of survival of\n",
      "\n",
      "the fittest for multiple generations of individuals, the (near-)optimal\n",
      "solutions about accuracy and latency are obtained.\n",
      "\n",
      "Fig. 4 shows solutions, obtained by GA-based DSE, for ResNet-20,\n",
      "ResNet-32, ResNet-56, and ResNet-110 on the CIFAR-10 dataset. The\n",
      "𝑥-axis and 𝑦-axis represent the normalized top-1 accuracy and latency,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "solutions about accuracy and latency are obtained.\n",
      "\n",
      "Fig. 4 shows solutions, obtained by GA-based DSE, for ResNet-20,\n",
      "ResNet-32, ResNet-56, and ResNet-110 on the CIFAR-10 dataset. The\n",
      "𝑥-axis and 𝑦-axis represent the normalized top-1 accuracy and latency,\n",
      "normalized to the top-1 accuracy and latency of the corresponding\n",
      "baseline model, respectively. The data, marked by the green dot, are\n",
      "the design points of the brute-force algorithm, and the data, marked\n",
      "by the red triangle, are the (near-)optimal results found by CoAxNN.\n",
      "The optimal solutions found by brute force are plotted by the boundary\n",
      "of the green and red regions. It can be observed that the (near-\n",
      ")optimal solutions searched by CoAxNN are close to this boundary,\n",
      "which demonstrates the effectiveness of CoAxNN. Therefore, CoAxNN\n",
      "can search for the model having the least computational cost in most\n",
      "cases and meeting the accuracy requirements by GA-based DSE.\n",
      "\n",
      "4.3. Performance of optimized models______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "which demonstrates the effectiveness of CoAxNN. Therefore, CoAxNN\n",
      "can search for the model having the least computational cost in most\n",
      "cases and meeting the accuracy requirements by GA-based DSE.\n",
      "\n",
      "4.3. Performance of optimized models\n",
      "\n",
      "We compare CoAxNN with state-of-the-art optimization methods\n",
      "such as ASRFP [38]. For the sake of fairness, the accuracy numbers\n",
      "are directly cited from their original papers. Different hyperparameters,\n",
      "such as learning rate, are used by distinct optimization methods, so the\n",
      "accuracy of the baseline model may be slightly different. Therefore,\n",
      "both the accuracy of the baseline model and the optimized model\n",
      "are shown in our experimental results, and ‘‘ACC. Drop’’ is used to\n",
      "represent the accuracy dropping of the model after optimization. A\n",
      "smaller number of ‘‘ACC. Drop’’ is better, and a negative number\n",
      "indicates the optimized model has higher accuracy than the baseline\n",
      "model. This is because model optimization has a regularization effect,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "represent the accuracy dropping of the model after optimization. A\n",
      "smaller number of ‘‘ACC. Drop’’ is better, and a negative number\n",
      "indicates the optimized model has higher accuracy than the baseline\n",
      "model. This is because model optimization has a regularization effect,\n",
      "which can reduce the overfitting of neural network models [2,18]. To\n",
      "avoid interference, we run each experiment three times and report the\n",
      "mean and standard deviation (mean ±std) of accuracy. Besides, we\n",
      "employ FLOPs to quantify the computational costs of neural network\n",
      "models.\n",
      "\n",
      "4.3.1. ResNets on CIFAR-10\n",
      "\n",
      "Table 1 shows the accuracy and FLOPs of ResNet-20/32/56/110 on\n",
      "the CIFAR-10 dataset. CoAxNN reduces the computational complexity\n",
      "of the original neural network model while meeting the accuracy\n",
      "requirements. The optimized ResNet-20, ResNet-32, ResNet-56, and\n",
      "ResNet-110 by CoAxNN achieves the FLOPs reduction from 4.06E7,\n",
      "6.89E7, 1.25E8, 2.53E8 (refer to Table 2) to 3.00E7, 4.89E7, 8.06E7,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "of the original neural network model while meeting the accuracy\n",
      "requirements. The optimized ResNet-20, ResNet-32, ResNet-56, and\n",
      "ResNet-110 by CoAxNN achieves the FLOPs reduction from 4.06E7,\n",
      "6.89E7, 1.25E8, 2.53E8 (refer to Table 2) to 3.00E7, 4.89E7, 8.06E7,\n",
      "1.63E8, reduced by 25.94%, 28.93%, 35.76%, 35.57% in computa-\n",
      "tional complexity, with the accuracy loss of 0.67%, 0.84%, 0.74%, and\n",
      "0.63%, respectively. Moreover, CoAxNN can exploit less computation\n",
      "to achieve top-1 accuracy that is comparable to other state-of-the-art\n",
      "model optimization methods. For example, ResNet-20 optimized by\n",
      "SFP demands the computational complexity of 2.43E7 FLOPs while\n",
      "reducing the top-1 accuracy by 1.37%. The optimized ResNet-20 by\n",
      "CoAxNN consumes less computation cost, i.e., 2.27E7 FLOPs, drops by\n",
      "1.39% in top-1 accuracy. CoAxNN reduces the computational cost of\n",
      "ResNet-32 to 3.44E7 FLOPs with a 1.58% accuracy drop. MIL spends\n",
      "more computations (4.70E7 FLOPs), reducing the top-1 accuracy by______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "CoAxNN consumes less computation cost, i.e., 2.27E7 FLOPs, drops by\n",
      "1.39% in top-1 accuracy. CoAxNN reduces the computational cost of\n",
      "ResNet-32 to 3.44E7 FLOPs with a 1.58% accuracy drop. MIL spends\n",
      "more computations (4.70E7 FLOPs), reducing the top-1 accuracy by\n",
      "1.59%. The compressed ResNet-56 by SFP achieves the FLOPs reduction\n",
      "of 52.60% and the accuracy loss of 1.33%. CoAxNN decreases the\n",
      "computational cost of ResNet-56 by 54.88% with a 1.22% accuracy\n",
      "drop. The optimized ResNet-110 by GAL reduces FLOPs by 48.50% with\n",
      "a 0.81% drop in top-1 accuracy. CoAxNN achieves a similar accuracy\n",
      "loss (0.88%) while reducing the computational complexity by 62.09%.\n",
      "For original neural network models, CoAxNN automatically searches\n",
      "for a reasonable configuration to effectively optimize the computational\n",
      "complexity while meeting the accuracy requirements. For the same ac-\n",
      "curacy requirement, CoAxNN reduces more computations than existing\n",
      "methods, achieving less resource consumption.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "for a reasonable configuration to effectively optimize the computational\n",
      "complexity while meeting the accuracy requirements. For the same ac-\n",
      "curacy requirement, CoAxNN reduces more computations than existing\n",
      "methods, achieving less resource consumption.\n",
      "\n",
      "We also analyze the FLOPs and the percentage of predicted images\n",
      "for different stages of optimized ResNet-20, ResNet-32, ResNet-56,\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029787\f\n",
      "G. Li et al.\n",
      "\n",
      "Fig. 4. The solutions with GA-based DSE on the CIFAR-10 dataset. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of\n",
      "this article.)\n",
      "\n",
      "Table 1\n",
      "Performance of optimized neural network models on CIFAR-10 (see [39–43]).\n",
      "\n",
      "Model\n",
      "\n",
      "Method\n",
      "\n",
      "Top-1 Acc.\n",
      "Baseline (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Accelerated (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Drop (%)\n",
      "\n",
      "ResNet-20\n",
      "\n",
      "ResNet-32\n",
      "\n",
      "ResNet-56\n",
      "\n",
      "ResNet-110\n",
      "\n",
      "MIL [39]\n",
      "SFP [2]\n",
      "FPGM [40]\n",
      "TAS [41]\n",
      "CoAxNN (0.67%)\n",
      "CoAxNN (1.39%)\n",
      "\n",
      "MIL [39]\n",
      "SFP [2]\n",
      "TAS [41]\n",
      "CoAxNN (0.84%)\n",
      "CoAxNN (1.58%)\n",
      "\n",
      "SFP [2]\n",
      "ASFP [8]\n",
      "CP [42]\n",
      "AMC [29]______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Model\n",
      "\n",
      "Method\n",
      "\n",
      "Top-1 Acc.\n",
      "Baseline (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Accelerated (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Drop (%)\n",
      "\n",
      "ResNet-20\n",
      "\n",
      "ResNet-32\n",
      "\n",
      "ResNet-56\n",
      "\n",
      "ResNet-110\n",
      "\n",
      "MIL [39]\n",
      "SFP [2]\n",
      "FPGM [40]\n",
      "TAS [41]\n",
      "CoAxNN (0.67%)\n",
      "CoAxNN (1.39%)\n",
      "\n",
      "MIL [39]\n",
      "SFP [2]\n",
      "TAS [41]\n",
      "CoAxNN (0.84%)\n",
      "CoAxNN (1.58%)\n",
      "\n",
      "SFP [2]\n",
      "ASFP [8]\n",
      "CP [42]\n",
      "AMC [29]\n",
      "CoAxNN (0.74%)\n",
      "CoAxNN (1.22%)\n",
      "\n",
      "SFP [2]\n",
      "ASRFP [38]\n",
      "TAS [41]\n",
      "GAL [43]\n",
      "CoAxNN (0.63%)\n",
      "CoAxNN (0.88%)\n",
      "\n",
      "92.49\n",
      "92.20\n",
      "92.20\n",
      "92.88\n",
      "92.68\n",
      "92.68\n",
      "\n",
      "92.33\n",
      "92.63\n",
      "93.89\n",
      "93.56\n",
      "93.56\n",
      "\n",
      "93.59\n",
      "93.59\n",
      "92.8\n",
      "92.8\n",
      "94.15\n",
      "94.15\n",
      "\n",
      "93.68\n",
      "94.33\n",
      "94.97\n",
      "93.26\n",
      "94.42\n",
      "94.42\n",
      "\n",
      "91.43\n",
      "90.83\n",
      "91.09\n",
      "90.97\n",
      "92.01 (±0.43)\n",
      "91.29 (±0.26)\n",
      "\n",
      "90.74\n",
      "90.08\n",
      "91.48\n",
      "92.72 (±0.13)\n",
      "91.98 (±0.41)\n",
      "\n",
      "92.26\n",
      "92.44\n",
      "90.9\n",
      "91.9\n",
      "93.41 (±0.05)\n",
      "92.93 (±0.25)\n",
      "\n",
      "92.90\n",
      "93.69\n",
      "94.33\n",
      "92.74\n",
      "93.79 (±0.36)\n",
      "93.54 (±0.17)\n",
      "\n",
      "1.06\n",
      "1.37\n",
      "1.11\n",
      "1.91\n",
      "0.67\n",
      "1.39\n",
      "\n",
      "1.59\n",
      "2.55\n",
      "2.41\n",
      "0.84\n",
      "1.58\n",
      "\n",
      "1.33\n",
      "1.15\n",
      "1.90\n",
      "0.90\n",
      "0.74\n",
      "1.22\n",
      "\n",
      "0.78\n",
      "0.67\n",
      "0.64\n",
      "0.81\n",
      "0.63\n",
      "0.88\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "2.61E7\n",
      "2.43E7\n",
      "2.43E7\n",
      "2.19E7\n",
      "3.00E7\n",
      "2.27E7\n",
      "\n",
      "4.70E7\n",
      "4.03E7\n",
      "4.08E7\n",
      "4.89E7\n",
      "3.44E7\n",
      "\n",
      "5.94E7\n",
      "5.94E7\n",
      "–\n",
      "6.29E7\n",
      "8.06E7\n",
      "5.66E7\n",
      "\n",
      "1.21E8\n",
      "1.21E8\n",
      "1.19E8\n",
      "–\n",
      "1.63E8\n",
      "9.59E7______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "93.54 (±0.17)\n",
      "\n",
      "1.06\n",
      "1.37\n",
      "1.11\n",
      "1.91\n",
      "0.67\n",
      "1.39\n",
      "\n",
      "1.59\n",
      "2.55\n",
      "2.41\n",
      "0.84\n",
      "1.58\n",
      "\n",
      "1.33\n",
      "1.15\n",
      "1.90\n",
      "0.90\n",
      "0.74\n",
      "1.22\n",
      "\n",
      "0.78\n",
      "0.67\n",
      "0.64\n",
      "0.81\n",
      "0.63\n",
      "0.88\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "2.61E7\n",
      "2.43E7\n",
      "2.43E7\n",
      "2.19E7\n",
      "3.00E7\n",
      "2.27E7\n",
      "\n",
      "4.70E7\n",
      "4.03E7\n",
      "4.08E7\n",
      "4.89E7\n",
      "3.44E7\n",
      "\n",
      "5.94E7\n",
      "5.94E7\n",
      "–\n",
      "6.29E7\n",
      "8.06E7\n",
      "5.66E7\n",
      "\n",
      "1.21E8\n",
      "1.21E8\n",
      "1.19E8\n",
      "–\n",
      "1.63E8\n",
      "9.59E7\n",
      "\n",
      "FLOPs ↓\n",
      "(%)\n",
      "\n",
      "36.00\n",
      "42.20\n",
      "42.20\n",
      "46.20\n",
      "25.94\n",
      "44.02\n",
      "\n",
      "31.20\n",
      "41.50\n",
      "41.00\n",
      "28.93\n",
      "49.98\n",
      "\n",
      "52.60\n",
      "52.60\n",
      "50.00\n",
      "50.00\n",
      "35.76\n",
      "54.88\n",
      "\n",
      "52.30\n",
      "52.30\n",
      "53.00\n",
      "48.50\n",
      "35.57\n",
      "62.09\n",
      "\n",
      "and ResNet-110, with an accuracy loss of 0.67%, 0.84%, 0.74%, and\n",
      "0.63%, respectively, as shown in the Table 2. Weighted average FLOPs\n",
      "(‘‘Avg. #FLOPs’’) are computed by exit percentage and exit FLOPs for\n",
      "each stage (e.g., 3.00E7 = 58.71% × 1.93E7 + 41.29% × 4.53E7),\n",
      "which indicates the average model performance on the entire dataset.\n",
      "CoAxNN employs distinct stages for different neural network models.\n",
      "The two stages are used for ResNet-20, and three stages are used\n",
      "for more complex ResNet-32, ResNet-56, and ResNet-110. The neural______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "which indicates the average model performance on the entire dataset.\n",
      "CoAxNN employs distinct stages for different neural network models.\n",
      "The two stages are used for ResNet-20, and three stages are used\n",
      "for more complex ResNet-32, ResNet-56, and ResNet-110. The neural\n",
      "network prediction finished at earlier stages costs less computational\n",
      "effort. Simple images, making up most of the dataset, are predicted by\n",
      "\n",
      "the first few stages, which reduces the computational complexity while\n",
      "ensuring accuracy.\n",
      "\n",
      "Besides, we show the configurations of the optimized models\n",
      "searched by the GA-based DSE, as shown in Table 3. The pruning rate,\n",
      "the number of stages, and the position and the threshold for each stage\n",
      "are reported. For the optimized ResNet-20, the pruning rate is 0, i.e., no\n",
      "pruning is performed, the number of stages is two, the position of the\n",
      "first stage is the end of the fourth residual block, the corresponding\n",
      "threshold is 0.3, and the second stage refers to the backbone neural______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "are reported. For the optimized ResNet-20, the pruning rate is 0, i.e., no\n",
      "pruning is performed, the number of stages is two, the position of the\n",
      "first stage is the end of the fourth residual block, the corresponding\n",
      "threshold is 0.3, and the second stage refers to the backbone neural\n",
      "network with no confidence threshold since images must be exited from\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029788\f\n",
      "G. Li et al.\n",
      "\n",
      "Table 2\n",
      "Analysis of optimized models on CIFAR-10.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Stages\n",
      "\n",
      "CoAxNN\n",
      "\n",
      "Percentage\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "Avg. #FLOPs\n",
      "\n",
      "Baseline\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "FLOPs ↓ (%)\n",
      "\n",
      "ResNet-20\n",
      "(0.67%)\n",
      "\n",
      "ResNet-32\n",
      "(0.84%)\n",
      "\n",
      "ResNet-56\n",
      "(0.74%)\n",
      "\n",
      "ResNet-110\n",
      "(0.63%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "Table 3\n",
      "Configurations optimized by GA-based DSE for CIFAR-10.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Configurations\n",
      "\n",
      "ResNet-20\n",
      "(0.67%)\n",
      "\n",
      "ResNet-32\n",
      "(0.84%)\n",
      "\n",
      "ResNet-56\n",
      "(0.74%)\n",
      "\n",
      "ResNet-110\n",
      "(0.63%)\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "0\n",
      "1\n",
      "4\n",
      "0.3\n",
      "\n",
      "0\n",
      "1\n",
      "6\n",
      "0.09______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Configurations\n",
      "\n",
      "ResNet-20\n",
      "(0.67%)\n",
      "\n",
      "ResNet-32\n",
      "(0.84%)\n",
      "\n",
      "ResNet-56\n",
      "(0.74%)\n",
      "\n",
      "ResNet-110\n",
      "(0.63%)\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "0\n",
      "1\n",
      "4\n",
      "0.3\n",
      "\n",
      "0\n",
      "1\n",
      "6\n",
      "0.09\n",
      "\n",
      "0\n",
      "1\n",
      "10\n",
      "0.07\n",
      "\n",
      "0\n",
      "1\n",
      "19\n",
      "0.07\n",
      "\n",
      "58.71%\n",
      "41.29%\n",
      "\n",
      "41.72%\n",
      "38.78%\n",
      "19.50%\n",
      "\n",
      "44.81%\n",
      "36.79%\n",
      "18.40%\n",
      "\n",
      "42.66%\n",
      "30.93%\n",
      "26.41%\n",
      "\n",
      "2\n",
      "–\n",
      "–\n",
      "\n",
      "2\n",
      "11\n",
      "0.1\n",
      "\n",
      "2\n",
      "19\n",
      "0.08\n",
      "\n",
      "2\n",
      "37\n",
      "0.015\n",
      "\n",
      "3\n",
      "–\n",
      "–\n",
      "\n",
      "3\n",
      "–\n",
      "–\n",
      "\n",
      "3\n",
      "–\n",
      "–\n",
      "\n",
      "3\n",
      "–\n",
      "–\n",
      "\n",
      "the last stage. Although ResNet-32, ResNet-56, and ResNet-110 are all\n",
      "optimized into three stages with a pruning rate of 0, the position and\n",
      "threshold of each stage are different. For the optimized ResNet-32, the\n",
      "threshold is 0.09, 0.1 for each stage where the position is the end of\n",
      "the 6, 11th residual block of the backbone network, respectively. For\n",
      "the optimized ResNet-56, the position of three stages is the end of the\n",
      "10, 19th residual block with the threshold of 0.07, 0.08. The optimized\n",
      "ResNet-110 uses three-stage with the threshold of 0.07, 0.017, where______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "the 6, 11th residual block of the backbone network, respectively. For\n",
      "the optimized ResNet-56, the position of three stages is the end of the\n",
      "10, 19th residual block with the threshold of 0.07, 0.08. The optimized\n",
      "ResNet-110 uses three-stage with the threshold of 0.07, 0.017, where\n",
      "the position is the end of the 19, 37th residual block.\n",
      "\n",
      "4.3.2. ResNets on CIFAR-100\n",
      "\n",
      "We evaluate CoAxNN on the CIFAR-100 dataset by ResNet-56 and\n",
      "ResNet-110, as shown in Table 4. Similarly, CoAxNN outperforms other\n",
      "state-of-the-art methods. For example, the computational complexity of\n",
      "optimized ResNet-110 by ASFP is 1.82E8 FLOPs, reduced by 28.20%\n",
      "compared to the original neural network model, leading to a 1.48%\n",
      "drop in top-1 accuracy. CoAxNN consumes 1.69E8 FLOPs, achieving\n",
      "a higher computation reduction of 33.34% and a lower accuracy loss\n",
      "of 1.30%. Although GHFP achieves a lower accuracy drop of 1.10%, it\n",
      "uses a higher computational complexity of 1.82E8 FLOPs. These results\n",
      "demonstrate the effectiveness of CoAxNN.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "a higher computation reduction of 33.34% and a lower accuracy loss\n",
      "of 1.30%. Although GHFP achieves a lower accuracy drop of 1.10%, it\n",
      "uses a higher computational complexity of 1.82E8 FLOPs. These results\n",
      "demonstrate the effectiveness of CoAxNN.\n",
      "\n",
      "In addition, Table 6 shows the configurations of the optimized mod-\n",
      "els with the accuracy loss of 0.98% and 1.30%, searched by CoAxNN,\n",
      "on the CIFAR-100 dataset. Despite the optimized ResNet-56 employing\n",
      "a three-stage and deactivating pruning-based strategy, which is as same\n",
      "as CIFAR-10, the thresholds are distinct. The optimized ResNet-56 uses\n",
      "three-stage with the threshold of 0.7 and 0.065. Besides, The optimized\n",
      "ResNet-110 adopts three-stage with a pruning rate of 0.1.\n",
      "\n",
      "We also study the FLOPs and the percentage of predicted images of\n",
      "the optimized model at each stage on CIFAR-100, as shown in Table 5.\n",
      "CoAxNN uses three stages for the ResNet-56 and the ResNet-110 as\n",
      "\n",
      "1.93E7\n",
      "4.53E7\n",
      "\n",
      "2.88E7\n",
      "5.59E7\n",
      "7.83E7\n",
      "\n",
      "4.76E7\n",
      "9.36E7\n",
      "1.35E8\n",
      "\n",
      "9.01E7\n",
      "1.79E8\n",
      "2.62E8\n",
      "\n",
      "3.00E7\n",
      "\n",
      "4.06E7______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "We also study the FLOPs and the percentage of predicted images of\n",
      "the optimized model at each stage on CIFAR-100, as shown in Table 5.\n",
      "CoAxNN uses three stages for the ResNet-56 and the ResNet-110 as\n",
      "\n",
      "1.93E7\n",
      "4.53E7\n",
      "\n",
      "2.88E7\n",
      "5.59E7\n",
      "7.83E7\n",
      "\n",
      "4.76E7\n",
      "9.36E7\n",
      "1.35E8\n",
      "\n",
      "9.01E7\n",
      "1.79E8\n",
      "2.62E8\n",
      "\n",
      "3.00E7\n",
      "\n",
      "4.06E7\n",
      "\n",
      "25.94\n",
      "\n",
      "4.89E7\n",
      "\n",
      "6.89E7\n",
      "\n",
      "28.93\n",
      "\n",
      "8.06E7\n",
      "\n",
      "1.25E8\n",
      "\n",
      "35.76\n",
      "\n",
      "1.63E8\n",
      "\n",
      "2.53E8\n",
      "\n",
      "35.57\n",
      "\n",
      "1 and \n",
      "\n",
      "same as CIFAR-10. But, since the CIFAR-100 is more complex, more\n",
      "complex models are required, leading to a smaller percentage of images\n",
      "predicted at \n",
      "2 than CIFAR-10. For example, for ResNet-56 on\n",
      "CIFAR-10, the percentages of predicted images by \n",
      "3 are\n",
      "44.81%, 36.79%, and 18.40%, respectively. For ResNet-56 on CIFAR-\n",
      "100, the percentages of predicted images by \n",
      "3 are 29.67%,\n",
      "32.85%, and 37.48%, respectively. For both CIFAR-10 and CIFAR-100,\n",
      "most of the images on the whole dataset are predicted by the first few\n",
      "stages with less computation. On the CIFAR-100, CoAxNN reduces the______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "100, the percentages of predicted images by \n",
      "3 are 29.67%,\n",
      "32.85%, and 37.48%, respectively. For both CIFAR-10 and CIFAR-100,\n",
      "most of the images on the whole dataset are predicted by the first few\n",
      "stages with less computation. On the CIFAR-100, CoAxNN reduces the\n",
      "FLOPs by 23.93% and 33.34%, with an accuracy drop of 0.98% and\n",
      "1.30%, for ResNet-56 and ResNet-110, respectively.\n",
      "\n",
      "2, and \n",
      "\n",
      "2, and \n",
      "\n",
      "1, \n",
      "\n",
      "1, \n",
      "\n",
      "4.3.3. ResNets on CINIC-10\n",
      "\n",
      "We utilize the CINIC-10 dataset, which consists of images from both\n",
      "CIFAR and ImageNet [46], avoiding the time-consuming process of\n",
      "model training on the entire ImageNet dataset, to facilitate experiments\n",
      "for complicated image classification scenarios. We evaluate CoAxNN on\n",
      "the CINIC-10 dataset by ResNet-18 and ResNet-50 models that are in\n",
      "line with the model structures on the ImageNet dataset.\n",
      "\n",
      "Table 7 shows the accuracy and computational cost of optimized\n",
      "models. For ResNet-18, when the FLOPs are reduced from 5.49E8______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "the CINIC-10 dataset by ResNet-18 and ResNet-50 models that are in\n",
      "line with the model structures on the ImageNet dataset.\n",
      "\n",
      "Table 7 shows the accuracy and computational cost of optimized\n",
      "models. For ResNet-18, when the FLOPs are reduced from 5.49E8\n",
      "(i.e., the computational cost of the original ResNet-18, refer to Table 8)\n",
      "to 2.21E8, reduced by 59.80%, the top-1 accuracy is dropped by 1.01%.\n",
      "If the accuracy requirement is higher, CoAxNN can achieve 0.50%\n",
      "accuracy loss while reducing the computational complexity by 43.71%\n",
      "for the ResNet-18. ResNet-50 with a large number of computations is\n",
      "improved by 0.10% in top-1 accuracy, and the corresponding FLOPs\n",
      "is reduced from 1.18E9 (i.e., the computational cost of the original\n",
      "ResNet-50, refer to Table 8) to 4.63E8, reduced by 60.75% in compu-\n",
      "tational complexity. We compare CoAxNN with state-of-the-art model\n",
      "optimization methods, FPC [47] and CCPrune [48]. FPC reduces the\n",
      "computational complexity by 40.48% (7.76E8 FLOPs) while increas-______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "ResNet-50, refer to Table 8) to 4.63E8, reduced by 60.75% in compu-\n",
      "tational complexity. We compare CoAxNN with state-of-the-art model\n",
      "optimization methods, FPC [47] and CCPrune [48]. FPC reduces the\n",
      "computational complexity by 40.48% (7.76E8 FLOPs) while increas-\n",
      "ing the top-1 accuracy by 1.14% for the ResNet-50 model. CCPrune\n",
      "increases the top-1 accuracy of the ResNet-50 model by 0.23% with\n",
      "a computational complexity of 7.44E8 FLOPs. CoAxNN reduces the\n",
      "computational complexity by 49.73% (5.93E8 FLOPs) with a 0.38%\n",
      "improvement in top-1 accuracy. By effectively combining stage-based\n",
      "with pruning-based approximate strategies, CoAxNN achieves better\n",
      "performance than existing methods.\n",
      "\n",
      "Moreover, we analyze the FLOPs and predicted images at each stage\n",
      "for the optimized ResNet-18 and ResNet-50 with a 1.01% and −0.10%\n",
      "accuracy drop respectively, as shown in Table 8. For the CINIC-10\n",
      "dataset, both the ResNet-18 and the ResNet-50 use four stages. More______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Moreover, we analyze the FLOPs and predicted images at each stage\n",
      "for the optimized ResNet-18 and ResNet-50 with a 1.01% and −0.10%\n",
      "accuracy drop respectively, as shown in Table 8. For the CINIC-10\n",
      "dataset, both the ResNet-18 and the ResNet-50 use four stages. More\n",
      "than 80% of the images are finished in the previous two stages, and\n",
      "less than 10% of images are predicted in the last stage.\n",
      "\n",
      "Table 9 shows the configurations of the ResNet-18 and the ResNet-\n",
      "50. ResNet-18 uses four-stage with thresholds of 0.23, 0.2, and 0.4,\n",
      "whose position is the end of the 3, 5, and 7th residual block, and the\n",
      "pruning rate is 0.3. When the sample does not exit from the first few\n",
      "stages, it must be exited from the last stage. Therefore, the last stage\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)1029789\f\n",
      "G. Li et al.\n",
      "\n",
      "Table 4\n",
      "Performance of optimized neural network models on CIFAR-100 (see [44,45]).\n",
      "\n",
      "Model\n",
      "\n",
      "Method\n",
      "\n",
      "Top-1 Acc.\n",
      "Baseline (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Accelerated (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Drop (%)\n",
      "\n",
      "ResNet-56\n",
      "\n",
      "ResNet-110\n",
      "\n",
      "MIL [39]\n",
      "CoAxNN (0.98%)______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "JournalofSystemsArchitecture143(2023)1029789\f\n",
      "G. Li et al.\n",
      "\n",
      "Table 4\n",
      "Performance of optimized neural network models on CIFAR-100 (see [44,45]).\n",
      "\n",
      "Model\n",
      "\n",
      "Method\n",
      "\n",
      "Top-1 Acc.\n",
      "Baseline (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Accelerated (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Drop (%)\n",
      "\n",
      "ResNet-56\n",
      "\n",
      "ResNet-110\n",
      "\n",
      "MIL [39]\n",
      "CoAxNN (0.98%)\n",
      "CoAxNN (2.36%)\n",
      "\n",
      "MIL [39]\n",
      "SFP [2]\n",
      "ASFP [8]\n",
      "ASRFP [38]\n",
      "GHFP [44]\n",
      "AHSG-HT [45]\n",
      "CoAxNN (1.30%)\n",
      "CoAxNN (3.42%)\n",
      "\n",
      "71.33\n",
      "72.75\n",
      "72.75\n",
      "\n",
      "72.79\n",
      "74.14\n",
      "74.39\n",
      "74.39\n",
      "74.39\n",
      "74.46\n",
      "74.17\n",
      "74.17\n",
      "\n",
      "68.37\n",
      "71.77 (±0.28)\n",
      "70.39 (±0.11)\n",
      "\n",
      "70.78\n",
      "71.28\n",
      "72.91\n",
      "73.02\n",
      "73.29\n",
      "72.74\n",
      "72.87 (±0.19)\n",
      "70.75 (±0.38)\n",
      "\n",
      "2.96\n",
      "0.98\n",
      "2.36\n",
      "\n",
      "2.01\n",
      "2.86\n",
      "1.48\n",
      "1.37\n",
      "1.10\n",
      "1.72\n",
      "1.30\n",
      "3.42\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "7.63E7\n",
      "9.55E7\n",
      "7.46E7\n",
      "\n",
      "1.73E8\n",
      "1.21E8\n",
      "1.82E8\n",
      "1.82E8\n",
      "1.82E8\n",
      "–\n",
      "1.69E8\n",
      "1.15E8\n",
      "\n",
      "FLOPs ↓\n",
      "(%)\n",
      "\n",
      "39.30\n",
      "23.93\n",
      "40.53\n",
      "\n",
      "31.30\n",
      "52.30\n",
      "28.20\n",
      "28.20\n",
      "28.20\n",
      "29.30\n",
      "33.34\n",
      "54.47\n",
      "\n",
      "Table 5\n",
      "Analysis of optimized models on CIFAR-100.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Stages\n",
      "\n",
      "CoAxNN\n",
      "\n",
      "Percentage\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "Avg. #FLOPs\n",
      "\n",
      "Baseline\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "FLOPs ↓ (%)\n",
      "\n",
      "ResNet-56\n",
      "(0.98%)\n",
      "\n",
      "ResNet-110\n",
      "(1.30%)\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "Table 6______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "(%)\n",
      "\n",
      "39.30\n",
      "23.93\n",
      "40.53\n",
      "\n",
      "31.30\n",
      "52.30\n",
      "28.20\n",
      "28.20\n",
      "28.20\n",
      "29.30\n",
      "33.34\n",
      "54.47\n",
      "\n",
      "Table 5\n",
      "Analysis of optimized models on CIFAR-100.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Stages\n",
      "\n",
      "CoAxNN\n",
      "\n",
      "Percentage\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "Avg. #FLOPs\n",
      "\n",
      "Baseline\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "FLOPs ↓ (%)\n",
      "\n",
      "ResNet-56\n",
      "(0.98%)\n",
      "\n",
      "ResNet-110\n",
      "(1.30%)\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "Table 6\n",
      "Configurations optimized by GA-based DSE for CIFAR-100.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Configurations\n",
      "\n",
      "ResNet-56\n",
      "(0.98%)\n",
      "\n",
      "ResNet-110\n",
      "(1.30%)\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "0\n",
      "1\n",
      "10\n",
      "0.7\n",
      "\n",
      "0.1\n",
      "1\n",
      "19\n",
      "0.73\n",
      "\n",
      "29.67%\n",
      "32.85%\n",
      "37.48%\n",
      "\n",
      "27.60%\n",
      "30.18%\n",
      "42.22%\n",
      "\n",
      "2\n",
      "19\n",
      "0.65\n",
      "\n",
      "2\n",
      "37\n",
      "0.62\n",
      "\n",
      "3\n",
      "–\n",
      "–\n",
      "\n",
      "3\n",
      "–\n",
      "–\n",
      "\n",
      "has no threshold value. The ResNet-34 uses four-stage with thresholds\n",
      "of 0.08, 0.09, and 0.09, whose position is the end of the 4, 8, and 14th\n",
      "residual block, and the pruning rate is 0.2.\n",
      "\n",
      "Summary. As shown in Tables 1, 4, and 7, CoAxNN, which auto-\n",
      "matically finds (near)-optimal configurations for effectively combining\n",
      "staging-based and pruning-based approximate strategies, is comparable______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "residual block, and the pruning rate is 0.2.\n",
      "\n",
      "Summary. As shown in Tables 1, 4, and 7, CoAxNN, which auto-\n",
      "matically finds (near)-optimal configurations for effectively combining\n",
      "staging-based and pruning-based approximate strategies, is comparable\n",
      "to the state-of-the-art methods. The staging-based approximate strate-\n",
      "gies perform adaptive inference for inputs according to conditions at\n",
      "run-time. The inference of simple input can be terminated with a good\n",
      "prediction confidence in the earlier stage, thereby avoiding remaining\n",
      "layerwise computations, so that the overall computation cost can be\n",
      "significantly reduced. However, the number of model parameters is\n",
      "still too large to be deployed on mobile devices. The pruning-based\n",
      "approximate strategies remove the unimportant weights or filters to\n",
      "gain a thinner model. However, the pruning method lacks the ability\n",
      "to configure the neural network dynamically, which will miss the\n",
      "opportunities to optimize the model inference. Based on these previ-______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "approximate strategies remove the unimportant weights or filters to\n",
      "gain a thinner model. However, the pruning method lacks the ability\n",
      "to configure the neural network dynamically, which will miss the\n",
      "opportunities to optimize the model inference. Based on these previ-\n",
      "ous mentioned optimization principles, CoAxNN automatically finds\n",
      "(near-)optimal configurations by GA-based DSE, making full use of the\n",
      "advantages of both, thus achieving efficient model optimization.\n",
      "\n",
      "4.4. Realistic performance of on-device inference\n",
      "\n",
      "To demonstrate the realistic speedup and energy savings of our\n",
      "approximate compressed multi-stage models, we evaluate the perfor-\n",
      "mance of models on a representative intelligent edge device, Jetson\n",
      "AGX Orin.\n",
      "\n",
      "4.76E7\n",
      "9.36E7\n",
      "1.35E8\n",
      "\n",
      "8.23E7\n",
      "1.59E8\n",
      "2.32E8\n",
      "\n",
      "9.55E7\n",
      "\n",
      "1.25E8\n",
      "\n",
      "23.93\n",
      "\n",
      "1.69E8\n",
      "\n",
      "2.53E8\n",
      "\n",
      "33.34\n",
      "\n",
      "For the measurement of inference latency, on the one hand, we pre-\n",
      "execute each neural network model 10 times to warm up the machine,\n",
      "and then repeat the single-batch inference 100 times to record the______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "4.76E7\n",
      "9.36E7\n",
      "1.35E8\n",
      "\n",
      "8.23E7\n",
      "1.59E8\n",
      "2.32E8\n",
      "\n",
      "9.55E7\n",
      "\n",
      "1.25E8\n",
      "\n",
      "23.93\n",
      "\n",
      "1.69E8\n",
      "\n",
      "2.53E8\n",
      "\n",
      "33.34\n",
      "\n",
      "For the measurement of inference latency, on the one hand, we pre-\n",
      "execute each neural network model 10 times to warm up the machine,\n",
      "and then repeat the single-batch inference 100 times to record the\n",
      "average execution time to reduce the interference, such as system\n",
      "initialization. On the other hand, after executing all the operators on\n",
      "the device we insert synchronous instructions to obtain timestamps,\n",
      "thus avoiding inaccurate measurements for inference time. Table 10\n",
      "depicts the inference latency for the optimized ResNet-20, ResNet-\n",
      "32, ResNet-56, and ResNet-110 by CoAxNN, respectively dropped by\n",
      "0.67%, 0.84%, 0.74%, and 0.63% in top-1 accuracy on the CIFAR-\n",
      "10 dataset. The results show that CoAxNN can accelerate ResNet-20,\n",
      "ResNet-32, ResNet-56, and ResNet-110 models by 1.33×, 1.34×, 1.53×,\n",
      "and 1.51×, respectively. In general, the larger models can obtain a more\n",
      "significant speedup.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "0.67%, 0.84%, 0.74%, and 0.63% in top-1 accuracy on the CIFAR-\n",
      "10 dataset. The results show that CoAxNN can accelerate ResNet-20,\n",
      "ResNet-32, ResNet-56, and ResNet-110 models by 1.33×, 1.34×, 1.53×,\n",
      "and 1.51×, respectively. In general, the larger models can obtain a more\n",
      "significant speedup.\n",
      "\n",
      "To analyze the energy consumption of optimized models, we use\n",
      "the jetson-stats3 to monitor the power of the system. We per-\n",
      "form 10 000 times single-batch inference for ResNet-20, ResNet-32,\n",
      "ResNet-56, and ResNet-110 on Jetson AGX Orin, and the instantaneous\n",
      "powers are obtained to multiply the average inference time per image\n",
      "to compute the energy consumption of models. Table 11 shows the\n",
      "energy consumption for ResNet-20, ResNet-32, ResNet-56, and ResNet-\n",
      "110 with the accuracy loss of 0.67%, 0.84%, 0.74%, and 0.63% on\n",
      "the CIFAR-10 dataset. CoAxNN reduces the energy consumption of\n",
      "ResNet-20, ResNet-32, ResNet-56, and ResNet-110 by 25.17%, 25.68%,\n",
      "34.61%, and 33.81%, respectively. The experimental results show that______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "110 with the accuracy loss of 0.67%, 0.84%, 0.74%, and 0.63% on\n",
      "the CIFAR-10 dataset. CoAxNN reduces the energy consumption of\n",
      "ResNet-20, ResNet-32, ResNet-56, and ResNet-110 by 25.17%, 25.68%,\n",
      "34.61%, and 33.81%, respectively. The experimental results show that\n",
      "the optimized models by CoAxNN can be improved in terms of energy\n",
      "consumption, and the more complex neural network models can save\n",
      "more energy.\n",
      "\n",
      "We also evaluate the realistic speedup and energy reduction of mod-\n",
      "els optimized by existing filter pruning approaches [2,8,11]. Tables 12\n",
      "and 13 show the execute latency and energy consumption of single-\n",
      "batch inference of optimized ResNet-20, ResNet-32, ResNet-56, and\n",
      "ResNet-110 by filter pruning with the accuracy loss of 2.32%, 1.12%,\n",
      "0.23%, and 0.10%, on the CIFAR-10 dataset, respectively. Compared\n",
      "with the baseline models, the optimized models have higher execution\n",
      "latency and more energy consumption. Although filter pruning can\n",
      "reduce theoretical computation costs and memory footprint, the opti-______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "0.23%, and 0.10%, on the CIFAR-10 dataset, respectively. Compared\n",
      "with the baseline models, the optimized models have higher execution\n",
      "latency and more energy consumption. Although filter pruning can\n",
      "reduce theoretical computation costs and memory footprint, the opti-\n",
      "mized models cannot obtain actual acceleration and energy reduction\n",
      "\n",
      "3 https://pypi.org/project/jetson-stats/.\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)10297810\f\n",
      "G. Li et al.\n",
      "\n",
      "Table 7\n",
      "Performance of optimized neural network models on CINIC-10.\n",
      "\n",
      "Model\n",
      "\n",
      "Method\n",
      "\n",
      "Top-1 Acc.\n",
      "Baseline (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Accelerated (%)\n",
      "\n",
      "Top-1 Acc.\n",
      "Drop (%)\n",
      "\n",
      "ResNet-18\n",
      "\n",
      "ResNet-50\n",
      "\n",
      "CoAxNN (0.50%)\n",
      "CoAxNN (1.01%)\n",
      "\n",
      "FPC [47]\n",
      "CCPrune [48]\n",
      "CoAxNN (−0.38%)\n",
      "CoAxNN (−0.10%)\n",
      "\n",
      "87.57\n",
      "87.57\n",
      "\n",
      "86.63\n",
      "88.30\n",
      "88.52\n",
      "88.52\n",
      "\n",
      "87.07 (±0.29)\n",
      "86.56 (±0.43)\n",
      "\n",
      "87.77\n",
      "88.53\n",
      "88.14 (±0.15)\n",
      "88.62 (±0.34)\n",
      "\n",
      "0.50\n",
      "1.01\n",
      "\n",
      "−1.14\n",
      "−0.23\n",
      "−0.38\n",
      "−0.10\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "3.09E8\n",
      "2.21E8\n",
      "\n",
      "7.76E8\n",
      "7.44E8\n",
      "5.93E8\n",
      "4.63E8\n",
      "\n",
      "FLOPs ↓\n",
      "(%)\n",
      "\n",
      "43.71\n",
      "59.80\n",
      "\n",
      "40.48\n",
      "–\n",
      "49.73\n",
      "60.75\n",
      "\n",
      "Table 8\n",
      "Analysis of optimized models on CINIC-10.\n",
      "\n",
      "Model (Acc.Drop)______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "86.63\n",
      "88.30\n",
      "88.52\n",
      "88.52\n",
      "\n",
      "87.07 (±0.29)\n",
      "86.56 (±0.43)\n",
      "\n",
      "87.77\n",
      "88.53\n",
      "88.14 (±0.15)\n",
      "88.62 (±0.34)\n",
      "\n",
      "0.50\n",
      "1.01\n",
      "\n",
      "−1.14\n",
      "−0.23\n",
      "−0.38\n",
      "−0.10\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "3.09E8\n",
      "2.21E8\n",
      "\n",
      "7.76E8\n",
      "7.44E8\n",
      "5.93E8\n",
      "4.63E8\n",
      "\n",
      "FLOPs ↓\n",
      "(%)\n",
      "\n",
      "43.71\n",
      "59.80\n",
      "\n",
      "40.48\n",
      "–\n",
      "49.73\n",
      "60.75\n",
      "\n",
      "Table 8\n",
      "Analysis of optimized models on CINIC-10.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Stages\n",
      "\n",
      "CoAxNN\n",
      "\n",
      "Percentage\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "Avg. #FLOPs\n",
      "\n",
      "Baseline\n",
      "\n",
      "#FLOPs\n",
      "\n",
      "FLOPs ↓ (%)\n",
      "\n",
      "ResNet-18\n",
      "(1.01%)\n",
      "\n",
      "ResNet-50\n",
      "(−0.10%)\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "50.86%\n",
      "30.96%\n",
      "13.13%\n",
      "5.05%\n",
      "\n",
      "39.90%\n",
      "41.58%\n",
      "9.27%\n",
      "9.26%\n",
      "\n",
      "1.35E8\n",
      "2.57E8\n",
      "3.79E8\n",
      "4.56E8\n",
      "\n",
      "2.11E8\n",
      "4.91E8\n",
      "8.66E8\n",
      "1.02E9\n",
      "\n",
      "2.21E8\n",
      "\n",
      "5.49E8\n",
      "\n",
      "59.80\n",
      "\n",
      "4.63E8\n",
      "\n",
      "1.18E9\n",
      "\n",
      "60.75\n",
      "\n",
      "Table 9\n",
      "Configurations optimized by GA-based DSE for CINIC-10.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Configurations\n",
      "\n",
      "ResNet-18\n",
      "(1.01%)\n",
      "\n",
      "ResNet-50\n",
      "(−0.10%)\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "0.3\n",
      "1\n",
      "3\n",
      "0.23\n",
      "\n",
      "0.2\n",
      "1\n",
      "4\n",
      "0.08\n",
      "\n",
      "2\n",
      "5\n",
      "0.2\n",
      "\n",
      "2\n",
      "8\n",
      "0.09\n",
      "\n",
      "3\n",
      "7\n",
      "0.4\n",
      "\n",
      "3\n",
      "14\n",
      "0.09\n",
      "\n",
      "4\n",
      "–\n",
      "–\n",
      "\n",
      "4\n",
      "–\n",
      "–\n",
      "\n",
      "Table 12\n",
      "Speedups of optimized models by existing pruning approaches [2,8,11] on Jetson AGX\n",
      "Orin.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Latency (ms)______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "ResNet-50\n",
      "(−0.10%)\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "Rate\n",
      "Stage\n",
      "Position\n",
      "Threshold\n",
      "\n",
      "0.3\n",
      "1\n",
      "3\n",
      "0.23\n",
      "\n",
      "0.2\n",
      "1\n",
      "4\n",
      "0.08\n",
      "\n",
      "2\n",
      "5\n",
      "0.2\n",
      "\n",
      "2\n",
      "8\n",
      "0.09\n",
      "\n",
      "3\n",
      "7\n",
      "0.4\n",
      "\n",
      "3\n",
      "14\n",
      "0.09\n",
      "\n",
      "4\n",
      "–\n",
      "–\n",
      "\n",
      "4\n",
      "–\n",
      "–\n",
      "\n",
      "Table 12\n",
      "Speedups of optimized models by existing pruning approaches [2,8,11] on Jetson AGX\n",
      "Orin.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Latency (ms)\n",
      "\n",
      "Speedup\n",
      "\n",
      "Baseline\n",
      "\n",
      "Filter pruning\n",
      "\n",
      "ResNet-20\n",
      "(2.32%)\n",
      "\n",
      "ResNet-32\n",
      "(1.12%)\n",
      "\n",
      "ResNet-56\n",
      "(0.23%)\n",
      "\n",
      "ResNet-110\n",
      "(0.10%)\n",
      "\n",
      "6.26\n",
      "\n",
      "9.55\n",
      "\n",
      "16.89\n",
      "\n",
      "32.33\n",
      "\n",
      "8.70\n",
      "\n",
      "13.73\n",
      "\n",
      "22.51\n",
      "\n",
      "42.59\n",
      "\n",
      "0.72\n",
      "\n",
      "0.70\n",
      "\n",
      "0.75\n",
      "\n",
      "0.76\n",
      "\n",
      "Table 10\n",
      "Speedups of optimized models by CoAxNN on Jetson AGX Orin.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Latency (ms)\n",
      "\n",
      "Speedup\n",
      "\n",
      "Baseline\n",
      "\n",
      "CoAxNN\n",
      "\n",
      "Table 13\n",
      "Energy reductions of optimized models by existing pruning approaches [2,8,11] on\n",
      "Jetson AGX Orin.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Energy (mJ)\n",
      "\n",
      "Reduction\n",
      "\n",
      "ResNet-20\n",
      "(0.67%)\n",
      "\n",
      "ResNet-32\n",
      "(0.84%)\n",
      "\n",
      "ResNet-56\n",
      "(0.74%)\n",
      "\n",
      "ResNet-110\n",
      "(0.63%)\n",
      "\n",
      "6.26\n",
      "\n",
      "9.55\n",
      "\n",
      "16.89\n",
      "\n",
      "32.33\n",
      "\n",
      "4.69\n",
      "\n",
      "7.11\n",
      "\n",
      "11.05\n",
      "\n",
      "21.4\n",
      "\n",
      "1.33\n",
      "\n",
      "1.34\n",
      "\n",
      "1.53\n",
      "\n",
      "1.51\n",
      "\n",
      "ResNet-20\n",
      "(2.32%)\n",
      "\n",
      "ResNet-32\n",
      "(1.12%)\n",
      "\n",
      "ResNet-56\n",
      "(0.23%)\n",
      "\n",
      "ResNet-110\n",
      "(0.10%)\n",
      "\n",
      "Baseline\n",
      "\n",
      "27.89\n",
      "\n",
      "42.79\n",
      "\n",
      "76.57______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Energy (mJ)\n",
      "\n",
      "Reduction\n",
      "\n",
      "ResNet-20\n",
      "(0.67%)\n",
      "\n",
      "ResNet-32\n",
      "(0.84%)\n",
      "\n",
      "ResNet-56\n",
      "(0.74%)\n",
      "\n",
      "ResNet-110\n",
      "(0.63%)\n",
      "\n",
      "6.26\n",
      "\n",
      "9.55\n",
      "\n",
      "16.89\n",
      "\n",
      "32.33\n",
      "\n",
      "4.69\n",
      "\n",
      "7.11\n",
      "\n",
      "11.05\n",
      "\n",
      "21.4\n",
      "\n",
      "1.33\n",
      "\n",
      "1.34\n",
      "\n",
      "1.53\n",
      "\n",
      "1.51\n",
      "\n",
      "ResNet-20\n",
      "(2.32%)\n",
      "\n",
      "ResNet-32\n",
      "(1.12%)\n",
      "\n",
      "ResNet-56\n",
      "(0.23%)\n",
      "\n",
      "ResNet-110\n",
      "(0.10%)\n",
      "\n",
      "Baseline\n",
      "\n",
      "27.89\n",
      "\n",
      "42.79\n",
      "\n",
      "76.57\n",
      "\n",
      "Filter pruning\n",
      "\n",
      "45.74\n",
      "\n",
      "72.47\n",
      "\n",
      "−63.99%\n",
      "\n",
      "−69.36%\n",
      "\n",
      "119.24\n",
      "\n",
      "−55.73%\n",
      "\n",
      "146.69\n",
      "\n",
      "225.34\n",
      "\n",
      "−53.61%\n",
      "\n",
      "Table 11\n",
      "Energy reductions of optimized models by CoAxNN on Jetson AGX Orin.\n",
      "\n",
      "Model (Acc.Drop)\n",
      "\n",
      "Energy (mJ)\n",
      "\n",
      "Reduction\n",
      "\n",
      "ResNet-20\n",
      "(0.67%)\n",
      "\n",
      "ResNet-32\n",
      "(0.84%)\n",
      "\n",
      "ResNet-56\n",
      "(0.74%)\n",
      "\n",
      "ResNet-110\n",
      "(0.63%)\n",
      "\n",
      "Baseline\n",
      "\n",
      "27.89\n",
      "\n",
      "42.79\n",
      "\n",
      "76.57\n",
      "\n",
      "146.69\n",
      "\n",
      "CoAxNN\n",
      "\n",
      "20.87\n",
      "\n",
      "31.8\n",
      "\n",
      "50.07\n",
      "\n",
      "97.10\n",
      "\n",
      "25.17%\n",
      "\n",
      "25.68%\n",
      "\n",
      "34.61%\n",
      "\n",
      "33.81%\n",
      "\n",
      "Fig. 5. Accuracy of the optimization model at different stages. ‘‘CoAxNN-ALL’’ and\n",
      "‘‘CoAxNN-ACT’’ denote the accuracy of the model at each stage on the whole dataset\n",
      "and on the images that satisfy the activation condition of the corresponding stage,\n",
      "respectively.\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)10297811\f\n",
      "G. Li et al.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "‘‘CoAxNN-ACT’’ denote the accuracy of the model at each stage on the whole dataset\n",
      "and on the images that satisfy the activation condition of the corresponding stage,\n",
      "respectively.\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)10297811\f\n",
      "G. Li et al.\n",
      "\n",
      "Fig. 6. Example images predicated correctly at different stages.\n",
      "\n",
      "Table 14\n",
      "Overheads of GA-based DSE.\n",
      "\n",
      "Model\n",
      "\n",
      "ResNet-20\n",
      "ResNet-32\n",
      "ResNet-56\n",
      "ResNet-110\n",
      "\n",
      "GA time (s)\n",
      "\n",
      "Training time (s)\n",
      "\n",
      "1.15\n",
      "1.60\n",
      "1.69\n",
      "1.46\n",
      "\n",
      "5472\n",
      "1813\n",
      "2720\n",
      "7712\n",
      "\n",
      "on Jetson AGX Orin. Therefore, the critical motivation of CoAxNN is to\n",
      "find a satisfying optimization configuration for practical scenarios.\n",
      "\n",
      "4.5. Ablation study\n",
      "\n",
      "Accuracy of CoAxNN models at different stages. We study the accu-\n",
      "racy of ResNet-56 optimized by CoAxNN at different stages, as shown\n",
      "in Fig. 5. In ‘‘CoAxNN-ALL’’, the accuracy of the model in the first few\n",
      "stages is lower than that of the baseline model. As the computational\n",
      "complexity of the model increases, the accuracy in the later stages______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "racy of ResNet-56 optimized by CoAxNN at different stages, as shown\n",
      "in Fig. 5. In ‘‘CoAxNN-ALL’’, the accuracy of the model in the first few\n",
      "stages is lower than that of the baseline model. As the computational\n",
      "complexity of the model increases, the accuracy in the later stages\n",
      "gradually converges to that of the baseline model. CoAxNN separates\n",
      "the prediction of simple and complex images by conditional activation,\n",
      "allowing simple images to exit from the first few stages and complex\n",
      "images to exit from the latter stages. In ‘‘CoAxNN-ACT’’, the accuracy\n",
      "of the first few stages becomes higher and even exceeds that of the\n",
      "baseline model, which indicates that the first few stages have sufficient\n",
      "ability to classify simple images. Besides, since complex images are\n",
      "predicted by the later stages, the accuracy of the last stage of the\n",
      "optimization model is lower than that of the baseline model.\n",
      "\n",
      "Visualization results at different stages. Fig. 6 depicts the predicted______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "ability to classify simple images. Besides, since complex images are\n",
      "predicted by the later stages, the accuracy of the last stage of the\n",
      "optimization model is lower than that of the baseline model.\n",
      "\n",
      "Visualization results at different stages. Fig. 6 depicts the predicted\n",
      "sample images for each stage of optimized ResNet-56 on CIFAR-10.\n",
      "The samples predicated at stage \n",
      "1 are relatively ‘‘easy’’, which have\n",
      "a small number of objects and clear background, whereas the samples\n",
      "predicated at stage \n",
      "3 are relatively ‘‘hard’’, which have various\n",
      "objects and complex background. CoAxNN can separate ‘‘easy’’ images\n",
      "consuming less effort from ‘‘hard’’ ones consuming more computation,\n",
      "significantly reducing computation costs for neural network models.\n",
      "\n",
      "2 and \n",
      "\n",
      "Overheads of GA-based DSE. We collect the latency of each operator\n",
      "of the neural network model on the edge device in the profiling phase\n",
      "beforehand to be used in GA-based search. We perform the model______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "significantly reducing computation costs for neural network models.\n",
      "\n",
      "2 and \n",
      "\n",
      "Overheads of GA-based DSE. We collect the latency of each operator\n",
      "of the neural network model on the edge device in the profiling phase\n",
      "beforehand to be used in GA-based search. We perform the model\n",
      "optimization processes, including model training and GA-based search,\n",
      "on a server with Intel Xeon CPUs and an Nvidia A100 GPU. The\n",
      "inference of optimized models is performed on edge devices such as\n",
      "Jetson AGX Orin. Table 14 shows the times for GA-based search and\n",
      "the time to train the model once during the model optimization. The\n",
      "GA-based DSE takes 1–2 s on the CPU platform, which is greatly less\n",
      "than model training (e.g., ResNet-20 takes 5472 s for training once).\n",
      "Therefore, the runtime overhead of the GA is negligible.\n",
      "\n",
      "5. Discussion\n",
      "\n",
      "Generality. CoAxNN is a generic framework for optimizing on-device\n",
      "deep learning via model approximation, which can be generalized\n",
      "to other intelligent tasks such as object detection [49]. In addition,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "Therefore, the runtime overhead of the GA is negligible.\n",
      "\n",
      "5. Discussion\n",
      "\n",
      "Generality. CoAxNN is a generic framework for optimizing on-device\n",
      "deep learning via model approximation, which can be generalized\n",
      "to other intelligent tasks such as object detection [49]. In addition,\n",
      "more approximate strategies such as knowledge distillation [50] can\n",
      "be integrated into CoAxNN to further optimize neural network models.\n",
      "\n",
      "Applicability. CoAxNN is system-independent, which not requires spe-\n",
      "cific software implementations and hardware design support. The op-\n",
      "timized models by CoAxNN can be directly deployed on the target\n",
      "platform, especially intelligent edge accelerators. Users can choose\n",
      "the (near)-optimal model according to the accuracy and performance\n",
      "requirements of intelligent tasks. Moreover, the time-consuming opti-\n",
      "mization process can be performed offline on high-performance servers,\n",
      "achieving efficient fine-tuning.\n",
      "\n",
      "Limitations. Although CoAxNN shows the advantages of combining______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "requirements of intelligent tasks. Moreover, the time-consuming opti-\n",
      "mization process can be performed offline on high-performance servers,\n",
      "achieving efficient fine-tuning.\n",
      "\n",
      "Limitations. Although CoAxNN shows the advantages of combining\n",
      "staging-based with pruning-based approximate strategies for model\n",
      "optimization, there is still room for further improvement. On one hand,\n",
      "the NSGA-III used in GA-based DSE cannot always find the optimal\n",
      "solutions for the goals of increasing accuracy and decreasing latency.\n",
      "We will explore other genetic algorithms such as NPGA [51] for multi-\n",
      "objective optimization. On the other hand, the fixed-rate filter pruning\n",
      "strategy is used in CoAxNN. Prior works [11] demonstrated that differ-\n",
      "ent layers have different sensitives for model accuracy. Setting different\n",
      "pruning ratios for different layers can potentially further improve the\n",
      "performance, which will be explored in future studies.\n",
      "\n",
      "6. Conclusion\n",
      "\n",
      "In this paper, we proposed an efficient optimization framework,______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "ent layers have different sensitives for model accuracy. Setting different\n",
      "pruning ratios for different layers can potentially further improve the\n",
      "performance, which will be explored in future studies.\n",
      "\n",
      "6. Conclusion\n",
      "\n",
      "In this paper, we proposed an efficient optimization framework,\n",
      "CoAxNN, which effectively combines staging-based with pruning-based\n",
      "approximate strategies for efficient model\n",
      "inference on resource-\n",
      "constrained edge devices. Evaluation with state-of-the-art CNN models\n",
      "demonstrates the effectiveness of CoAxNN, which can significantly im-\n",
      "prove the performance with trivial accuracy loss. We plan to integrate\n",
      "more model approximate strategies into CoAxNN in future work.\n",
      "\n",
      "Declaration of competing interest\n",
      "\n",
      "The authors declare that they have no known competing finan-\n",
      "cial interests or personal relationships that could have appeared to\n",
      "influence the work reported in this paper.\n",
      "\n",
      "Data availability\n",
      "\n",
      "Data will be made available on request.\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)10297812\f\n",
      "G. Li et al.______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "______________________________________________________________\n",
      "The authors declare that they have no known competing finan-\n",
      "cial interests or personal relationships that could have appeared to\n",
      "influence the work reported in this paper.\n",
      "\n",
      "Data availability\n",
      "\n",
      "Data will be made available on request.\n",
      "\n",
      "JournalofSystemsArchitecture143(2023)10297812\f\n",
      "G. Li et al.\n",
      "\n",
      "Acknowledgments\n",
      "\n",
      "This work is supported by the National Key R&D Program of China\n",
      "(2021ZD0110101), the National Natural Science Foundation of China\n",
      "(62232015, 62302479), the China Postdoctoral Science Foundation\n",
      "(2023M733566), and the CCF-Baidu Open Fund, China.______________________________________________________________\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in splits:\n",
    "    print(\"______________________________________________________________\\n\" + s + \"______________________________________________________________\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
