{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5g8SefEpeAf",
    "outputId": "1d0ded39-2f64-4a79-c389-7724ccfb58fb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting arxiv\n",
      "  Downloading arxiv-2.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading PyMuPDF-1.24.3-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/aribra/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.56-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/aribra/.local/lib/python3.10/site-packages (from langchain) (1.26.2)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/aribra/.local/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/aribra/.local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Collecting feedparser==6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sgmllib3k (from feedparser==6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/aribra/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Collecting PyMuPDFb==1.24.3 (from pymupdf)\n",
      "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aribra/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/aribra/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/aribra/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/lib/python3/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDF-1.24.3-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=dca8e884084e5662d66346e444b68027cb4fdcf57f98766a2e2a05ca8dcc7927\n",
      "  Stored in directory: /home/aribra/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, typing-inspect, requests, PyMuPDFb, pydantic-core, packaging, orjson, multidict, jsonpatch, greenlet, frozenlist, feedparser, async-timeout, annotated-types, yarl, SQLAlchemy, pymupdf, pydantic, marshmallow, arxiv, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openxlab 0.0.32 requires requests~=2.28.2, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyMuPDFb-1.24.3 SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 arxiv-2.1.0 async-timeout-4.0.3 dataclasses-json-0.6.6 feedparser-6.0.10 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.56 marshmallow-3.21.2 multidict-6.0.5 orjson-3.10.3 packaging-23.2 pydantic-2.7.1 pydantic-core-2.18.2 pymupdf-1.24.3 requests-2.31.0 sgmllib3k-1.0.0 typing-inspect-0.9.0 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain arxiv pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/aribra/.local/lib/python3.10/site-packages (from pdfminer.six) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six)\n",
      "  Downloading cryptography-42.0.7-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/aribra/.local/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/aribra/.local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-42.0.7-cp39-abi3-manylinux_2_28_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: cryptography, pdfminer.six\n",
      "Successfully installed cryptography-42.0.7 pdfminer.six-20231228\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PDFMinerLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_putput_name = \"train_MK_FuturePhysics_Book.csv\"\n",
    "# book = PDFMinerLoader(file_path='pdfs/Michio-Kaku-FuturePhysics-Book.pdf').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_putput_name = \"train_MK_Physics_of_The_Impossible_Book.csv\"\n",
    "# book = PDFMinerLoader(file_path='pdfs/Michio-Kaku-Physics-of-The-Impossible-Book.pdf').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_putput_name = \"train_MK_Hyperspace_Book.csv\"\n",
    "# book = PDFMinerLoader(file_path='pdfs/HYPERSPACE_text_book.pdf').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_putput_name = \"train_MK_Physics_of_The_Mind_Book.csv\"\n",
    "book = PDFMinerLoader(file_path='pdfs/THE_SCIENTIFIC_QUEST TO_UNDERSTAND_ENHANCE_AND_EMPOWER_THE_MIND.pdf').load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = book[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_text = book[0].page_content.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "temp = all_text\n",
    "while True:\n",
    "    print(ix)\n",
    "    all_text = all_text.replace(\"  \", \" \")\n",
    "    if temp == all_text:\n",
    "        break\n",
    "    temp = all_text\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " future, to \n",
      "calculate the future position of moving objects. This was a difficult \n",
      "problem, requiring him to create an entirely new branch of mathematics, \n",
      "called calculus. Using this new mathematics, Newton was then able to \n",
      "predict the trajectory of not just the moon, but also Halley’s Comet and \n",
      "the planets. Since then, scientists have used Newton’s laws to simulate \n",
      "the future path of moving objects, from cannonballs, machines, \n",
      "automobiles, and rockets to asteroids and meteors, and even stars and \n",
      "galaxies. \n",
      "\n",
      "The success or failure of a model depends on how faithfully it \n",
      "reproduces the basic parameters of the original. In this case, the basic \n",
      "parameter was the location of the apple and the moon in space and time. \n",
      "By allowing this parameter to evolve (i.e., letting time move forward), \n",
      "Newton unlocked, for the first time in history, the action of moving \n",
      "\n",
      "\f\n",
      "bodies, which is one of the most important discoveries in science. \n",
      "\n",
      "Models are useful, until they are replaced by even more accurate \n",
      "models described by better parameters. Einstein replaced Newton’s \n",
      "\n",
      "picture of forces acting on apples and moons with a new model based on \n",
      "a new parameter, the curvature of space and time. An apple moved not \n",
      "because the Earth exerted a force on it, but because the fabric of space \n",
      "and time was stretched by the Earth, so the apple was simply moving \n",
      "along the surface of a curved space-time. From this, Einstein could then \n",
      "simulate the future of the entire universe. Now, with computers, we can \n",
      "run simulations of this model into the future and create gorgeous \n",
      "pictures presenting the collisions of black holes. \n",
      "\n",
      "Let us now incorporate this basic strategy into a new theory of \n",
      "consciousness. \n",
      "\n",
      "DEFINITION OF CONSCIOUSNESS \n",
      "\n",
      "I’ve taken bits and pieces from previous descriptions of consciousness in \n",
      "the fields of neurology and biology in order to define consciousness as \n",
      "follows: \n",
      "\n",
      "Consciousness is the process of creating a model of the world \n",
      "using multiple feedback loops in v\n"
     ]
    }
   ],
   "source": [
    "print(book[0].page_content[100000:102000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "book[0].page_content = all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " future, to \n",
      "calculate the future position of moving objects. This was a difficult \n",
      "problem, requiring him to create an entirely new branch of mathematics, \n",
      "called calculus. Using this new mathematics, Newton was then able to \n",
      "predict the trajectory of not just the moon, but also Halley’s Comet and \n",
      "the planets. Since then, scientists have used Newton’s laws to simulate \n",
      "the future path of moving objects, from cannonballs, machines, \n",
      "automobiles, and rockets to asteroids and meteors, and even stars and \n",
      "galaxies. \n",
      "\n",
      "The success or failure of a model depends on how faithfully it \n",
      "reproduces the basic parameters of the original. In this case, the basic \n",
      "parameter was the location of the apple and the moon in space and time. \n",
      "By allowing this parameter to evolve (i.e., letting time move forward), \n",
      "Newton unlocked, for the first time in history, the action of moving \n",
      "\n",
      "\f\n",
      "bodies, which is one of the most important discoveries in science. \n",
      "\n",
      "Models are useful, until they are replaced by even more accurate \n",
      "models described by better parameters. Einstein replaced Newton’s \n",
      "\n",
      "picture of forces acting on apples and moons with a new model based on \n",
      "a new parameter, the curvature of space and time. An apple moved not \n",
      "because the Earth exerted a force on it, but because the fabric of space \n",
      "and time was stretched by the Earth, so the apple was simply moving \n",
      "along the surface of a curved space-time. From this, Einstein could then \n",
      "simulate the future of the entire universe. Now, with computers, we can \n",
      "run simulations of this model into the future and create gorgeous \n",
      "pictures presenting the collisions of black holes. \n",
      "\n",
      "Let us now incorporate this basic strategy into a new theory of \n",
      "consciousness. \n",
      "\n",
      "DEFINITION OF CONSCIOUSNESS \n",
      "\n",
      "I’ve taken bits and pieces from previous descriptions of consciousness in \n",
      "the fields of neurology and biology in order to define consciousness as \n",
      "follows: \n",
      "\n",
      "Consciousness is the process of creating a model of the world \n",
      "using multiple feedback loops in v\n"
     ]
    }
   ],
   "source": [
    "print(book[0].page_content[100000:102000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "id": "Fem6SSK7u8Cp"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap  = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "_-AhB_DGvQp0"
   },
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMr_BcmTvL6q",
    "outputId": "c9af435d-b70f-456c-ca44-e3c239983954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1053"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n",
      "1020\n",
      "1020\n",
      "1020\n",
      "1020\n",
      "1020\n"
     ]
    }
   ],
   "source": [
    "for s in splits:\n",
    "    ls = len(s.page_content)\n",
    "    if ls >= 1020:\n",
    "        print(ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DR. MICHIO KAMI \\n\\nPROFESSOR OF THEORETICAL PHYSICS \\nCITY UNIVERSITY OI : NEW YORK \\n\\nTHE SCIENTIFIC QUEST TO UNDERSTAND \\nENHANCE, AND EMPOWER THE MIND \\n\\nDOUBLEPAY \\n\\nNEW YORK LONDON TORONTO \\n\\nSYDNEY AUCKLAND \\n\\nCopyright © 2014 by Michio Kaku \\n\\nAll rights reserved. Published in the United States by Doubleday, a division of Random House, \\nLLC, New York, and in Canada by Random House of Canada Limited, Toronto, Penguin Random \\nHouse companies. \\n\\nwww.doubleday.com \\n\\ndoubleday and the portrayal of an anchor with a dolphin are registered trademarks of Random \\nHouse, LLC. \\n\\nIllustrations by Jeffrey L. Ward \\nJacket design by Michael J. Windsor \\n\\n\\x0cJacket illustration © CLIP AREA/Custom media/Shutterstock \\nLIBRARY OF CONGRESS CATALOGING-IN-PUBLICATION DATA \\nKaku, Michio. \\n\\nThe future of the mind : the scientific quest to understand, enhance, and empower the mind / \\nDr. Michio Kaku, professor of Theoretical Physics, City University of New York. — First edition, \\npages cm \\n\\nIncludes bibliographical references.'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Includes bibliographical references. \\n\\n1. Neuropsychology. 2. Mind and body—Research. \\n\\n3. Brain—Mathematical models. 4. Cognitive neuroscience. \\n\\n5. Brain-computer interfaces. I. Title. \\nqp360.k 325 2014 \\n612.8—dc23 \\n\\n2013017338 \\n\\nISBN 978-0-385-53082-8 (hardcover) ISBN 978-0-385-53083-5 (eBook) \\n\\nv3.1 \\n\\nThis book is dedicated to my loving wife, Shizue, \\n\\nand my daughters, Michelle and Alyson \\n\\nCONTENTS \\n\\nCover \\n\\nTitle Page \\n\\nCopyright \\n\\nDedication \\n\\nACKNOWLEDGMENTS \\n\\nINTRODUCTION \\n\\n\\x0cBOOK I: THE MIND AND CONSCIOUSNESS \\n\\n1 UNLOCKING THE MIND \\n\\n2 CONSCIOUSNESS—A PHYSICIST’S VIEWPOINT \\n\\nBOOK II: MIND OVER MATTER \\n\\n3 TELEPATHY: A PENNY FOR YOUR THOUGHTS \\n\\n4 TELEKINESIS: MIND CONTROLLING MATTER \\n\\n5 MEMORIES AND THOUGHTS MADE TO ORDER \\n\\n6 EINSTEIN’S BRAIN AND ENHANCING OUR INTELLIGENCE \\n\\nBOOK III: ALTERED CONSCIOUSNESS \\n\\n7 IN YOUR DREAMS \\n\\n8 CAN THE MIND BE CONTROLLED? \\n\\n9 ALTERED STATES OF CONSCIOUSNESS \\n\\n10 THE ARTIFICIAL MIND AND SILICON CONSCIOUSNESS \\n\\n11 REVERSE ENGINEERING THE BRAIN'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "Q5H2AHi3S7H5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([split.page_content for split in splits], columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GefSHuVvTED_",
    "outputId": "d4be44b8-d13b-4931-826e-57b510f53aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1053, 1)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2UA4pgUQTE6j",
    "outputId": "ac7c8858-5a27-4361-be3e-3eb74e947211"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR. MICHIO KAMI \\n\\nPROFESSOR OF THEORETICAL P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Includes bibliographical references. \\n\\n1. Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 THE ARTIFICIAL MIND AND SILICON CONSCIOUSNE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peter Doherty, Nobel laureate, St. Jude Childr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marcia Bartusiak, author of Einstein’s Unfinis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  DR. MICHIO KAMI \\n\\nPROFESSOR OF THEORETICAL P...\n",
       "1  Includes bibliographical references. \\n\\n1. Ne...\n",
       "2  10 THE ARTIFICIAL MIND AND SILICON CONSCIOUSNE...\n",
       "3  Peter Doherty, Nobel laureate, St. Jude Childr...\n",
       "4  Marcia Bartusiak, author of Einstein’s Unfinis..."
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "B9lgulVpSPyd"
   },
   "outputs": [],
   "source": [
    "df.to_csv(csv_putput_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPouJr1iTRUY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
